<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习之超参数</title>
      <link href="/2019/12/30/shen-du-xue-xi-zhi-chao-can-shu/"/>
      <url>/2019/12/30/shen-du-xue-xi-zhi-chao-can-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="一、什么是超参数"><a href="#一、什么是超参数" class="headerlink" title="一、什么是超参数"></a>一、什么是超参数</h1><p>​    超参数是我们在将学习算法应用于数据集之前需要设置的变量。超参数的一个挑战在于,它不存在适用于所有地方的万能数字,每个任务和数据集的最佳数字各不相同。<br>​    一般来讲, 我们可以将超参数分为两类, 第一类是优化器超参数,它们是与优化和训练过程相关的变量,而非模型本身。这些包括学习率、minibatch大小以及训练迭代或 epoch 次数。 第二类是模型超参数。</p><h1 id="二、学习率"><a href="#二、学习率" class="headerlink" title="二、学习率"></a>二、学习率</h1><p>学习率是最重要的一个超参数, 即使你将他人构建的模型应用于 自己的数据集 你也会发现你可能需要尝试多个不同的学习率值才能使模型正确训练。</p><p>如果你归一化模型的输入，一个好的起始点通常是 0.01。这些是学习率的通常假设0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001。</p><p>学习率用于控制梯度下降的幅度，根据选取的学习率的不同，梯度下降的误差会呈现出不同的情况:</p><ul><li><p>如果我们选择的学习率小于理想的学习率,没关系,我们的模型将继续学习 直到找到权重的最佳值。但是,如果学习率太小,那么我们的训练误差就会降低的非常慢。很明显，在这种情况下我们需要做的是提高学习率 。</p></li><li><p>另一种情况是，如果我们选择一个大于理想学习率的学习率，更新的值将会越过理想的权重值。下一次更新时它会在反方向越过最佳值，也就是误差来回震荡,  但它会越来越靠近最佳值，可能最终会收敛到一个合理的值。</p></li><li><p>但是如果我们选择的学习率比理想学习率大很多，比如两倍以上，这就会产生问题。在这种情况下 我们会看到权重采取较大的步长 它不仅越过理想权值 而且实际上离我们每步获得的最佳误差越来越远。所以如果我们的训练误差在增加,不妨试试降低学习率，看看会发生什么 </p></li></ul><p>我们实际上无法保证误差曲线会是整洁的 U 形。事实上，它们会成为更复杂的形状。而且学习算法可能会错误地将局部最小值当做最佳值进行收敛 </p><p>下面我们来看一个在调整学习率时经常会遇到的一个具体情形，假设我们选择了一个合理的学习率，它可以降低误差但只能到某一个点，在那之后就无法下降了，尽管它还没到达底部，它会一直在两个值之间震荡，她们优于刚开始训练时的误差但却不是此模型的最佳值。在这种情况下，让我们的训练算法降低整个训练过程的学习率会比较有用，此技术叫作学习率衰减。这么做的直观方式是线性降低学习率，假设每5个epoch减半，也可以按指数方式降低学习率，例如 每8个epoch对学习率乘以0.1, 除了之间降低学习率外还有一些聪明的学习算法如自适应学习率，不仅在需要时降低学习率，还在学习率太低时升高它。</p><h1 id="三、mini-batch"><a href="#三、mini-batch" class="headerlink" title="三、mini-batch"></a>三、mini-batch</h1><p>​     一直以来人们都在争论哪种做法更好, 一种是在线随机训练, 在数据集中随机选择一条样本,然后仅用这一个样本进行前向传递,计算误差,然后反向传播并设置所有参数的调整数值，然后重复执行这个过程 。另一种是将整个数据集作为输入，使用数据集中所有示例的误差来计算整个数据集的梯度，这叫做批量训练 。</p><p>​    如今普遍使用的抽象是设置一个 mini-batch 大小，那么在线训练的mini-batch 大小就为 1，而批量训练的 mini-batch大小与训练集中的示例数量相同 。我们可以将 mini-batch 大小设置为1到数据集数量之间的任意值，32通常是一个不错的选择 。</p><p><img src="01.png" alt></p><p>​    较大的mini-batch可以更好的代表数据集整体的方向，会提高矩阵乘法的计算速度，但这也会占用更多的内存。较小的 mini-batch大小会使误差计算中有更多的噪声,但是此噪声通常有助于防止误差陷入局部最小值。</p><p><img src="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B6%85%E5%8F%82%E6%95%B0/02.png" alt></p><p>从上图中可以看出：</p><p>随着mini-batch的增大，训练一个epoch的时间越来越少</p><p>随着mini-batch的增大，达到同一准确率所花费的时间越来越多</p><p>一篇名为 “Systematic evaluation of CNN advances on the ImageNet” 的文章显示，在学习率相同的情况下，mini-batch越大，模型的准确度越低。这不仅在于 minibatch 大小的影响，而当我们改变批量大小时还需要改变学习率 。如果我们在增加批量大小的同时调整学习率，可以看到准确度会随批量大小增加而下降，不过只是轻微的下降 。<br>所以总结来说， 32 至 256是不错的初始值选择</p><h1 id="四、隐藏单元和层的数量"><a href="#四、隐藏单元和层的数量" class="headerlink" title="四、隐藏单元和层的数量"></a>四、隐藏单元和层的数量</h1><p>隐藏单元的数据量越多越好，但如果过多往往会导致过拟合。所以如果你的模型无法训练就向它添加更多隐藏层并跟踪验证误差，直到验证误差开始变大。</p><p> Andrej Karpathy 告诉我们在实践中三层神经网络的性能往往优于两层网络的性能，但继续增加层却作用不大 。不过，卷积神经网络除外，它们往往是越深性能越好。</p><h1 id="五、超参数的验证"><a href="#五、超参数的验证" class="headerlink" title="五、超参数的验证"></a>五、超参数的验证</h1><p>为什么不能用测试数据评估超参数的性能呢？这是因为如果使用测试数据调整超参数，超参数的值会对测试数据发生过拟合。换句话说，用测试数据确认超参数的值的“好坏”，就会导致超参数的值被调整为只拟合测试数据。这样话，可能就会得到不能拟合其他数据、泛化能力低的模型。 </p><p>因此，调整超参数时，必须使用超参数专用的确认数据。用于调整超参数的数据，一般称为验证数据（validation data）。 </p><p>训练数据用于参数（权重和偏置）的学习，验证数据用于超参数的性能评估。为了确认泛化能力，要在最后使用（比较理想的是只用一次）测试数据。</p><p><strong>超参数的最优化</strong></p><p>进行超参数的最优化时，逐渐缩小超参数的“好值”的存在范围非常重要。所谓逐渐缩小范围，是指一开始先大致设定一个范围，从这个范围中随机选出一个超参数（采样），用这个采样到的值进行识别精度的评估；然后，多次重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。通过重复这一操作，就可以逐渐确定超参数的合适范围。  </p><p><strong>最优化的步骤</strong></p><p>步骤0, 设定超参数的范围。<br>步骤1, 从设定的超参数范围中随机采样。<br>步骤2, 使用步骤1中采样到的超参数的值进行学习，通过验证数据评估识别精<br>度（但是要将epoch设置得很小）。<br>步骤3, 重复步骤1和步骤2（100次等），根据它们的识别精度的结果，缩小超参数的范围。 </p><p>反复进行上述操作，不断缩小超参数的范围，在缩小到一定程度时，从该范围中选出一个超参数的值。这就是进行超参数的最优化的一种方法。 </p><p>在超参数的最优化中，如果需要更精炼的方法，可以使用贝叶斯最优化（Bayesian optimization）。贝叶斯最优化运用以贝叶斯定理为中心的数学理论，能够更加严密、高效地进行最优化。详细内容请参 考 论 文“Practical Bayesian Optimization of Machine Learning Algorithms” 等。 </p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习之过拟合</title>
      <link href="/2019/12/29/shen-du-xue-xi-zhi-guo-ni-he/"/>
      <url>/2019/12/29/shen-du-xue-xi-zhi-guo-ni-he/</url>
      
        <content type="html"><![CDATA[<h1 id="一、过拟合"><a href="#一、过拟合" class="headerlink" title="一、过拟合"></a>一、过拟合</h1><p>机器学习的问题中，过拟合是一个很常见的问题。过拟合指的是只能拟合训练数据，但不能很好地拟合不包含在训练数据中的其他数据的状态。机器学习的目标是提高泛化能力，即便是没有包含在训练数据里的未观测数据，也希望模型可以进行正确的识别。</p><p>发生过拟合的原因，主要有以下两个：</p><ul><li>模型拥有大量参数、表现力强（模型太复杂）</li><li>训练数据少</li></ul><h1 id="二、如何减少过拟合"><a href="#二、如何减少过拟合" class="headerlink" title="二、如何减少过拟合"></a>二、如何减少过拟合</h1><h2 id="1、获取更多数据"><a href="#1、获取更多数据" class="headerlink" title="1、获取更多数据"></a>1、获取更多数据</h2><p>​    获取更多的数据，从源头上解决问题，比如数据增强</p><h2 id="2、正则化"><a href="#2、正则化" class="headerlink" title="2、正则化"></a>2、正则化</h2><p>​    该方法通过在学习过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是因为权重参数取值过大才发生的。</p><p><strong>L1正则化</strong><br>$$<br>L_1(\theta) = loss(\theta) + \lambda\sum_{i=1}^n|w_i|<br>$$<br><strong>L2正则化(权值衰减)</strong><br>$$<br>L_2(\theta) = loss(\theta) + \lambda\sum_{i=1}^nw_i^2<br>$$</p><ul><li>L1减少的是一个常量，L2减少的是权重的固定比例</li><li>L1使权重稀疏，L2使权重平滑，一句话总结: L1会趋向于产生少量的特征，而其他特征都是0, 而L2则会选择更多的特征，这些特征都会接近于0。</li><li>实践中L2正则化通常优于L1正则化</li></ul><h2 id="3、权重初始化"><a href="#3、权重初始化" class="headerlink" title="3、权重初始化"></a>3、权重初始化</h2><p>上面介绍抑制过拟合、提高泛化能力的技巧——权值衰减（weight decay）。简单地说，权值衰减就是一种以减小权重参数的值为目的进行学习<br>的方法。通过减小权重参数的值来抑制过拟合的发生。 </p><p>如果想减小权重的值，一开始就将初始值设为较小的值才是正途。 </p><p>为什么不能将权重初始值设为0呢？严格地说，为什么不能将权重初始<br>值设成一样的值呢？这是因为在误差反向传播法中，所有的权重值都会进行<br>相同的更新。 为了防止“权重均一化”，必须随机生成初始值。 </p><p>各层的激活值的分布都要求有适当的广度。为什么呢？因为通过在各层间传递多样性的数据，神经网络可以进行高效的学习。反过来，如果传递的是有所偏向的数据，就会出现梯度消失或者“表现力受限”的问题，导致学习可能无法顺利进行。 </p><p>Xavier：如果前一层的节点数为n，则初始值使用标准差为$\frac{1}{\sqrt n}$的分布 </p><p>Xavier初始值是以激活函数是线性函数为前提而推导出来的。因为sigmoid函数和 tanh函数左右对称，且中央附近可以视作线性函数，所以适合使用Xavier初始值。但当激活函数使用ReLU时，一般推荐使用ReLU专用的初始值，也称为“He初始值”。当前一层的节点数为n时， He初始值使用标准差为 $\frac{2}{\sqrt n}$的高斯分布。当Xavier初始值是$\frac{1}{\sqrt n}$ 时，（直观上）可以解释为，因为ReLU的负值区域的值为0，为了使它更有广度，所以需要2倍的系数 </p><h2 id="4、Batch-Normalization"><a href="#4、Batch-Normalization" class="headerlink" title="4、Batch Normalization"></a>4、Batch Normalization</h2><p>如果设定了合适的权重初始值，则各层的激活值分布会有适当的广度，从而可以顺利地进行学习。那么，为了使各层拥有适当的广度，“强制性”地调整激活值的分布会怎样呢？实际上， Batch Normalization方法就是基于这个想法而产生的。 </p><p>为什么Batch Norm这么惹人注目呢？因为Batch Norm有以下优点。</p><ul><li>可以使学习快速进行（可以增大学习率）。</li><li>不那么依赖初始值（对于初始值不用那么神经质）。</li><li>抑制过拟合（降低Dropout等的必要性）。 </li></ul><p><img src="02.png" alt></p><p>Batch Norm，顾名思义，以进行学习时的mini-batch为单位，按minibatch进行正规化。具体而言，就是进行使数据分布的均值为0、方差为1的正规化。 </p><p>接着， Batch Norm层会对正规化后的数据进行缩放和平移的变换，用<br>数学式可以如下表示。<br>$$<br>y_i \leftarrow \gamma x_i + \beta<br>$$<br>这里， γ和β是参数。一开始γ = 1， β = 0，然后再通过学习调整到合<br>适的值。 </p><h2 id="5、Dropout"><a href="#5、Dropout" class="headerlink" title="5、Dropout"></a>5、Dropout</h2><p>​    如果网络模型变的很复杂，只使用权值衰减就很难应对了。在这种情下，我们经常使用Dropout方法。</p><p><img src="01.png" alt></p><p>​    Dropout是一种在学习的过程中随机删除神经元的方法。训练时，随机<br>选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递</p><h2 id="6、早期停止法"><a href="#6、早期停止法" class="headerlink" title="6、早期停止法"></a>6、早期停止法</h2><p>我们将训练集和测试集相对于每个epoch误差绘制成图表，对于第一epoch，因为模型是完全随机的，所以训练误差和测试误差都很大，随着epoch的增加，训练曲线一直在下降，因为模型越来越好的拟合数据，测试误差先下降后升高，最低点之前模型欠拟合，之后模型过拟合，因为模型开始记住数据。所以我们只要在测试曲线达到最低点时停止训练就可以避免过拟合</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/skyfsm/p/8456968.html" target="_blank" rel="noopener">https://www.cnblogs.com/skyfsm/p/8456968.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习之CNN模型演化</title>
      <link href="/2019/12/02/shen-du-xue-xi-zhi-cnn-mo-xing-yan-hua/"/>
      <url>/2019/12/02/shen-du-xue-xi-zhi-cnn-mo-xing-yan-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="前沿"><a href="#前沿" class="headerlink" title="前沿"></a>前沿</h1><h1 id="一、LeNet"><a href="#一、LeNet" class="headerlink" title="一、LeNet"></a>一、LeNet</h1><p>1998年LeCun发布了LeNet网络架构，从而揭开了深度学习的神秘面纱。</p><p>​    <img src="c1.png" alt></p><p>和“现在的CNN”相比， LeNet有几个不同点。</p><ul><li><p>第一个不同点在于激活函数。 LeNet中使用sigmoid函数，而现在的CNN中主要使用ReLU函数。</p></li><li><p>第二个不同点在于池化层。原始的LeNet中使用子采样（subsampling）缩小中间数据的大小，而现在的CNN中Max池化是主流。</p></li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> keras<span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Flatten<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token comment" spellcheck="true">#load the MNIST dataset from keras datasets</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Process data</span>X_train <span class="token operator">=</span> X_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Expend dimension for 1 cahnnel image</span>X_test <span class="token operator">=</span> X_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Expend dimension for 1 cahnnel image</span>X_train <span class="token operator">=</span> X_train <span class="token operator">/</span> <span class="token number">255</span> <span class="token comment" spellcheck="true"># Normalize</span>X_test <span class="token operator">=</span> X_test <span class="token operator">/</span> <span class="token number">255</span> <span class="token comment" spellcheck="true"># Normalize</span><span class="token comment" spellcheck="true">#One hot encoding</span>y_train <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Build LetNet model with Keras</span><span class="token keyword">def</span> <span class="token function">LetNet</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># initialize the model</span>    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># first layer, convolution and pooling</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filters<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># second layer, convolution and pooling</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filters<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Fully connection layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'tanh'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'tanh'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># softmax classifier</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> modelLetNet_model <span class="token operator">=</span> LetNet<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>LetNet_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>LetNet_model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span class="token punctuation">,</span>loss <span class="token operator">=</span> <span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Strat training</span>History <span class="token operator">=</span> LetNet_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>validation_data<span class="token operator">=</span><span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Plot Loss and accuracy</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="二、AlexNet"><a href="#二、AlexNet" class="headerlink" title="二、AlexNet"></a>二、AlexNet</h1><p>2012年，Alex Krizhevsky发表了AlexNet，相对比LeNet它的网络层次更加深，从LeNet的5层到AlexNet的8层，更重要的是AlexNet还赢得了2012年的ImageNet竞赛的第一。AlexNet不仅比LeNet的神经网络层数更多更深，并且可以学习更复杂的图像高维特征。</p><p>​    <img src="c2.png" alt></p><p>AlexNet叠有多个卷积层和池化层，最后经由全连接层输出结果。虽然<br>结构上AlexNet和LeNet没有大的不同，但有以下几点差异。</p><ul><li>激活函数使用ReLU。</li><li>使用进行局部正规化的LRN（Local Response Normalization）层</li><li>使用Dropout</li><li>引入max pooling</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> keras<span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span>Dropout<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token comment" spellcheck="true">#Load oxflower17 dataset</span><span class="token keyword">import</span> tflearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>oxflower17 <span class="token keyword">as</span> oxflower17<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitx<span class="token punctuation">,</span> y <span class="token operator">=</span> oxflower17<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Split train and test data</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Data augumentation with Keras tools</span><span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGeneratorimg_gen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>    rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>    shear_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    zoom_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Build AlexNet model</span><span class="token keyword">def</span> <span class="token function">AlexNet</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#First Convolution and Pooling layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span>height<span class="token punctuation">,</span>depth<span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Second Convolution and Pooling layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Three Convolution layer and Pooling Layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Fully connection layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Classfication layer</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> modelAlexNet_model <span class="token operator">=</span> AlexNet<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">)</span>AlexNet_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>AlexNet_model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.00001</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span class="token punctuation">,</span>loss <span class="token operator">=</span> <span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Start training using dataaugumentation generator</span>History <span class="token operator">=</span> AlexNet_model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>img_gen<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>X_train<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                      steps_per_epoch <span class="token operator">=</span> len<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">16</span><span class="token punctuation">,</span> validation_data <span class="token operator">=</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">30</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Plot Loss and Accuracy</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="三、Network-in-network"><a href="#三、Network-in-network" class="headerlink" title="三、Network-in-network"></a>三、Network-in-network</h1><p>2013年年尾，Min Lin提出了在卷积后面再跟一个1x1的卷积核对图像进行卷积，这就是<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1312.4400" target="_blank" rel="noopener">Network-in-network</a>的核心思想了。NiN在每次卷积完之后使用，目的是为了在进入下一层的时候合并更多的卷积特征，减少网络参数、同样的内存可以存储更大的网络。</p><p><strong>1x1卷积核的作用</strong></p><ul><li><p>缩放通道的大小</p><p>通过控制卷积核的数量达到通道数大小的放缩。而池化层只能改变高度和宽度，无法改变通道数。</p></li><li><p>增加非线性</p><p>1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性，使得网络可以表达更加复杂的特征。</p></li><li><p>减少参数</p><p>在Inception Network中，由于需要进行较多的卷积运算，计算量很大，可以通过引入1×1确保效果的同时减少计算量。</p></li></ul><h1 id="四、VGG"><a href="#四、VGG" class="headerlink" title="四、VGG"></a>四、VGG</h1><p>VGG 在 2014 年的ILSVRC比赛中最终获得了第 2 名的成绩.</p><p>​    <img src="c3.png" alt></p><p><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.1556" target="_blank" rel="noopener">VGG</a>的创新是使用3x3的小型卷积核连续卷积。重复进行“卷积层重叠2次到4次，再通过池化层将大小减半”的处理，最后经由全连接层输出结果。</p><p>​    <img src="c4.png" alt></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> keras<span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span>Dropout<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token comment" spellcheck="true">#Load oxflower17 dataset</span><span class="token keyword">import</span> tflearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>oxflower17 <span class="token keyword">as</span> oxflower17<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitx<span class="token punctuation">,</span> y <span class="token operator">=</span> oxflower17<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Split train and test data</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Data augumentation with Keras tools</span><span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGeneratorimg_gen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>    rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>    shear_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    zoom_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Build VGG16Net model</span><span class="token keyword">def</span> <span class="token function">VGG16Net</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">17</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> modelVGG16_model <span class="token operator">=</span> VGG16Net<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">)</span>VGG16_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>VGG16_model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.00001</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span class="token punctuation">,</span>loss <span class="token operator">=</span> <span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Start training using dataaugumentation generator</span>History <span class="token operator">=</span> VGG16_model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>img_gen<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>X_train<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                      steps_per_epoch <span class="token operator">=</span> len<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">16</span><span class="token punctuation">,</span> validation_data <span class="token operator">=</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">30</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Plot Loss and Accuracy</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="五、GoogLeNet"><a href="#五、GoogLeNet" class="headerlink" title="五、GoogLeNet"></a>五、GoogLeNet</h1><p>2014年，在google工作的Christian Szegedy为了找到一个深度神经网络结构能够有效地减少计算资源，于是有了这个<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1409.4842" target="_blank" rel="noopener">GoogleNet</a>了（也叫做Inception V1）。在 2014 年的ILSVRC比赛中最终获得了第 1名的成绩.</p><p>​    <img src="c6.png" alt></p><p>​    <img src="c5.png" alt></p><p>GoogLeNet的特征:</p><ul><li>Inception结构使用了多个大小不同的滤波器（和池化），<br>最后再合并它们的结果</li><li>最重要的是使用了1×1卷积核（NiN）来减少后续并行操作的特征数量。这个思想现在叫做“bottleneck layer”。</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> keras<span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>BatchNormalization<span class="token punctuation">,</span>AveragePooling2D<span class="token punctuation">,</span>concatenate<span class="token punctuation">,</span>Input<span class="token punctuation">,</span> concatenate<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model<span class="token punctuation">,</span>load_model<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token comment" spellcheck="true">#Load oxflower17 dataset</span><span class="token keyword">import</span> tflearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>oxflower17 <span class="token keyword">as</span> oxflower17<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitx<span class="token punctuation">,</span> y <span class="token operator">=</span> oxflower17<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Split train and test data</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Data augumentation with Keras tools</span><span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGeneratorimg_gen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>    rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>    shear_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    zoom_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Define convolution with batchnromalization</span><span class="token keyword">def</span> <span class="token function">Conv2d_BN</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> nb_filter<span class="token punctuation">,</span>kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> name <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>        bn_name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">'_bn'</span>        conv_name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">'_conv'</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        bn_name <span class="token operator">=</span> None        conv_name <span class="token operator">=</span> None    x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>nb_filter<span class="token punctuation">,</span>kernel_size<span class="token punctuation">,</span>padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>strides<span class="token operator">=</span>strides<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span>name<span class="token operator">=</span>conv_name<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>name<span class="token operator">=</span>bn_name<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#Define Inception structure</span><span class="token keyword">def</span> <span class="token function">Inception</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter_para<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token punctuation">(</span>branch1<span class="token punctuation">,</span>branch2<span class="token punctuation">,</span>branch3<span class="token punctuation">,</span>branch4<span class="token punctuation">)</span><span class="token operator">=</span> nb_filter_para    branch1x1 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    branch3x3 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    branch3x3 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>    branch5x5 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch3<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    branch5x5 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch3<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>branch5x5<span class="token punctuation">)</span>    branchpool <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    branchpool <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>branch4<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">(</span>branchpool<span class="token punctuation">)</span>    x <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>branch1x1<span class="token punctuation">,</span>branch3x3<span class="token punctuation">,</span>branch5x5<span class="token punctuation">,</span>branchpool<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#Build InceptionV1 model</span><span class="token keyword">def</span> <span class="token function">InceptionV1</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    inpt <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span>height<span class="token punctuation">,</span>depth<span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>inpt<span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">192</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 3a 28x28x256</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">192</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 3b 28x28x480</span>    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#14x14x480</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span><span class="token number">208</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">48</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 4a 14x14x512</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">160</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 4a 14x14x512</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 4a 14x14x512</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">144</span><span class="token punctuation">,</span><span class="token number">288</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 4a 14x14x528</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">160</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 4a 14x14x832</span>    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#7x7x832</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">160</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 5a 7x7x832</span>    x <span class="token operator">=</span> Inception<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span><span class="token number">384</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">48</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Inception 5b 7x7x1024</span>    <span class="token comment" spellcheck="true">#Using AveragePooling replace flatten</span>    x <span class="token operator">=</span> AveragePooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    model<span class="token operator">=</span>Model<span class="token punctuation">(</span>input<span class="token operator">=</span>inpt<span class="token punctuation">,</span>output<span class="token operator">=</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> modelInceptionV1_model <span class="token operator">=</span> InceptionV1<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">)</span>InceptionV1_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>InceptionV1_model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.00001</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span class="token punctuation">,</span>loss <span class="token operator">=</span> <span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>History <span class="token operator">=</span> InceptionV1_model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>img_gen<span class="token punctuation">.</span>flow<span class="token punctuation">(</span>X_train<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>steps_per_epoch <span class="token operator">=</span> len<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">16</span><span class="token punctuation">,</span> validation_data <span class="token operator">=</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">30</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Plot Loss and accuracy</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="六、Inception-V3（还有V2"><a href="#六、Inception-V3（还有V2" class="headerlink" title="六、Inception V3（还有V2)"></a>六、Inception V3（还有V2)</h1><p>Christian 和他的团队都是非常高产的研究人员。2015 年 2 月，<strong>Batch-normalized Inception</strong> 被引入作为<strong>Inception V2</strong>。</p><p>2015年12月，他们发布了一个新版本的GoogLeNet(<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Inception V3</a>)模块和相应的架构，并且更好地解释了原来的GoogLeNet架构，GoogLeNet原始思想：</p><ul><li>通过构建平衡深度和宽度的网络，最大化网络的信息流。在进入pooling层之前增加feature maps</li><li>当网络层数深度增加时，特征的数量或层的宽度也相对应地增加</li><li>在每一层使用宽度增加以增加下一层之前的特征的组合</li><li><strong>只使用3x3卷积</strong></li></ul><p>因此最后的模型就变成这样了：</p><p>​    <img src="c7.png" alt></p><h1 id="七、ResNet"><a href="#七、ResNet" class="headerlink" title="七、ResNet"></a>七、ResNet</h1><p>2015年12月<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1512.03385v1.pdf" target="_blank" rel="noopener">ResNet</a>发表了，时间上大概与Inception v3网络一起发表的。</p><p><img src="c8.png" alt></p><p><strong>ResNet的特征:</strong></p><ul><li><p>原来的2层卷积层的输出F(x)变成了F(x) + x。通过引入这种快捷结构，即使加深层，也能高效地学习。</p><p>因为快捷结构只是原封不动地传递输入数据，所以反向传播时会将来自上游的梯度原封不动地传向下游。这里的重点是不对来自上游的度进行任何处理，将其原封不动地传向下游。因此，基于快捷结构，不用担心梯度会变小（或变大），能够向前一层传递“有意义的梯度”。通过这个快捷结构，之前因为加深层而导致的梯度变小的梯度消失问题就有望得到缓解。</p></li><li><p>使用1x1卷积核减少特征数</p></li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> keras<span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span>Dropout<span class="token punctuation">,</span>BatchNormalization<span class="token punctuation">,</span>AveragePooling2D<span class="token punctuation">,</span>concatenate<span class="token punctuation">,</span>Input<span class="token punctuation">,</span> concatenate<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model<span class="token punctuation">,</span>load_model<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token comment" spellcheck="true">#Load oxflower17 dataset</span><span class="token keyword">import</span> tflearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>oxflower17 <span class="token keyword">as</span> oxflower17<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitx<span class="token punctuation">,</span> y <span class="token operator">=</span> oxflower17<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Split train and test data</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Data augumentation with Keras tools</span><span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGeneratorimg_gen <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>    rescale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>    shear_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    zoom_range<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>    horizontal_flip<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Define convolution with batchnromalization</span><span class="token keyword">def</span> <span class="token function">Conv2d_BN</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> nb_filter<span class="token punctuation">,</span>kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> name <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>        bn_name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">'_bn'</span>        conv_name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">'_conv'</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        bn_name <span class="token operator">=</span> None        conv_name <span class="token operator">=</span> None    x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>nb_filter<span class="token punctuation">,</span>kernel_size<span class="token punctuation">,</span>padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>strides<span class="token operator">=</span>strides<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span>name<span class="token operator">=</span>conv_name<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>name<span class="token operator">=</span>bn_name<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#Define Residual Block for ResNet34(2 convolution layers)</span><span class="token keyword">def</span> <span class="token function">Residual_Block</span><span class="token punctuation">(</span>input_model<span class="token punctuation">,</span>nb_filter<span class="token punctuation">,</span>kernel_size<span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> with_conv_shortcut <span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>input_model<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span>nb_filter<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>strides<span class="token operator">=</span>strides<span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>x<span class="token punctuation">,</span> nb_filter<span class="token operator">=</span>nb_filter<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#need convolution on shortcut for add different channel</span>    <span class="token keyword">if</span> with_conv_shortcut<span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>input_model<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span>nb_filter<span class="token punctuation">,</span>strides<span class="token operator">=</span>strides<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">)</span>        x <span class="token operator">=</span> add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span>shortcut<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">else</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> add<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span>input_model<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#Built ResNet34</span><span class="token keyword">def</span> <span class="token function">ResNet34</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    Img <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span>height<span class="token punctuation">,</span>depth<span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Conv2d_BN<span class="token punctuation">(</span>Img<span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">#Residual conv2_x ouput 56x56x64 </span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Residual conv3_x ouput 28x28x128 </span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>with_conv_shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># need do convolution to add different channel</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Residual conv4_x ouput 14x14x256</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>with_conv_shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># need do convolution to add different channel</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Residual conv5_x ouput 7x7x512</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>with_conv_shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> Residual_Block<span class="token punctuation">(</span>x<span class="token punctuation">,</span>nb_filter<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#Using AveragePooling replace flatten</span>    x <span class="token operator">=</span> GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    model<span class="token operator">=</span>Model<span class="token punctuation">(</span>input<span class="token operator">=</span>Img<span class="token punctuation">,</span>output<span class="token operator">=</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> model  <span class="token comment" spellcheck="true">#Plot Loss and accuracy</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>History<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'model loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="八、Xception"><a href="#八、Xception" class="headerlink" title="八、Xception"></a>八、Xception</h1><p>2016年８月</p><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1610.02357" target="_blank" rel="noopener">Xception</a>是google继Inception后提出的对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>​    <a href="https://www.cnblogs.com/CZiFan/p/9490565.html" target="_blank" rel="noopener">https://www.cnblogs.com/CZiFan/p/9490565.html</a></p><p>​    <a href="https://www.zhihu.com/question/53727257/answer/136261195" target="_blank" rel="noopener">https://www.zhihu.com/question/53727257/answer/136261195</a></p><p>​    <a href="https://blog.csdn.net/u014380165/article/details/75142710" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/75142710</a></p><p>​    <a href="https://medium.com/雞雞與兔兔的工程世界/機器學習-ml-note-cnn演化史-alexnet-vgg-inception-resnet-keras-coding-668f74879306" target="_blank" rel="noopener">https://medium.com/%E9%9B%9E%E9%9B%9E%E8%88%87%E5%85%94%E5%85%94%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%B8%96%E7%95%8C/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-ml-note-cnn%E6%BC%94%E5%8C%96%E5%8F%B2-alexnet-vgg-inception-resnet-keras-coding-668f74879306</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习之优化算法</title>
      <link href="/2019/11/28/shen-du-xue-xi-zhi-you-hua-suan-fa/"/>
      <url>/2019/11/28/shen-du-xue-xi-zhi-you-hua-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>​    神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻找最优参数的问题，解决这个问题的过程称为最优化(optimization).</p><p>​    使用参数的梯度，沿梯度方向更新参数，并重复这个步骤多次，从而逐渐靠近最优参数，这个过程称为随机梯度下降法(stochastic gradient descent)，简称SGD。 但SGD也有它的缺点，根据不同的问题，也存在比SGD更好的方法。</p><h1 id="二、SGD"><a href="#二、SGD" class="headerlink" title="二、SGD"></a>二、SGD</h1><p>深度学习中的SGD指mini-batch gradient descent。 在训练过程中，采用固定的学习率.</p><p>数学公式<br>$$<br>W \leftarrow W - \eta \frac {\partial L}{\partial W}<br>$$</p><p><strong>代码实现</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SGD</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""随机梯度下降法（Stochastic Gradient Descent）"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        更新权重        :param params: 权重, 字典，params['W1'], ..        :param grads: 梯度, 字典, grads['w1']        :return:        """</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> params<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>SGD的缺点</strong></p><ol><li>选择合适的learning rate 比较困难, 且对所有的参数更新使用同样的learning rate.</li><li>SGD容易收敛到局部最优，并且在某些情况下可能被困在鞍点.</li></ol><p>​    <img src="sgd.png" alt></p><p>​    为了改正SGD的缺点，下面我们将使用Momentum、 AdaGrad、Adam这3种方法来取代SGD。</p><h1 id="三、Momentum"><a href="#三、Momentum" class="headerlink" title="三、Momentum"></a>三、Momentum</h1><p>​    Momentum是”动量”的意思。动量方法旨在加速学习，特别是在面对小而连续的梯度但是含有很多噪声的时候。动量模拟了物体运动的惯性，即在更新的时候在一定程度上会考虑之前更新的方向，同时利用当前batch的梯度微调最终的结果。这样则可以在一定程度上增加稳定性，从而更快的学习。</p><p><strong>数学公式</strong><br>$$<br>\upsilon \leftarrow \alpha \upsilon - \eta \frac {\partial L}{\partial W}<br>$$</p><p>$$<br>W \leftarrow W + \upsilon<br>$$</p><p><strong>代码实现</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Momentum</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Momentum SGD"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr        self<span class="token punctuation">.</span>momentum <span class="token operator">=</span> momentum        self<span class="token punctuation">.</span>v <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>v <span class="token keyword">is</span> None<span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 初始化v</span>            self<span class="token punctuation">.</span>v <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                                                self<span class="token punctuation">.</span>v<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>val<span class="token punctuation">)</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> params<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>v<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>momentum<span class="token operator">*</span>self<span class="token punctuation">.</span>v<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>lr<span class="token operator">*</span>grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span>             params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>v<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="mom.png" alt></p><p>​                                <strong>基于Momentum的最优化的更新路径</strong></p><p>​    和SGD相比，我们发现“之”字形的“程度”减轻了。这是因为虽然x轴方向上受到的力非常小，但是一直在同一方向上受力，所以朝同一个方向会有一定的加速。反过来，虽然y轴方向上受到的力很大，但是因为交互地受到正方向和反方向的力，它们会互相抵消，所以y轴方向上的速度不稳定。因此，和SGD时的情形相比，可以更快地朝x轴方向靠近，减弱“之”字形的变动程度。</p><p><strong>特点</strong></p><ol><li>下降初期，使用上一次参数更新，当下降方向一致时能够加速学习。</li><li>下降中后期，在局部最小值附近来回震荡，gradient$\rightarrow$0</li><li>在梯度改变方向时，能减少更新。</li><li>总体而言，momentum能够在相关方向上加速学习，抑制震荡，从而加速收敛。</li></ol><h1 id="四、AdaGrad"><a href="#四、AdaGrad" class="headerlink" title="四、AdaGrad"></a>四、AdaGrad</h1><p>​    在神经网络的学习中，学习率（数学式中记为η）的值很重要。学习率过小，会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能正确进行。</p><p>​    在关于学习率的有效技巧中，有一种被称为学习率衰减（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。</p><p>​    和Momentum直接把动量累加到梯度上不同，它是通过动量逐步减小学习率的值，使得最后的值在最小值附近，更加接近收敛点。</p><p><strong>数学公式</strong><br>$$<br>h \leftarrow h + \frac {\partial L}{\partial W} \cdot \frac {\partial L}{\partial W}<br>$$</p><p>$$<br>W \leftarrow W - \eta \frac {1}{\sqrt h}\frac {\partial L}{\partial W}<br>$$</p><p>在更新参数时，通过乘以$\frac {1}{\sqrt h}$ ，就可以调整学习的尺度</p><p><strong>代码实现</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AdaGrad</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""AdaGrad"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr        self<span class="token punctuation">.</span>h <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>h <span class="token keyword">is</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>h <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>val<span class="token punctuation">)</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> params<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">+=</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span>            params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 为了防止当self.h[key]中有0时，将0用作除数的情况。添加了1e-7</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    <img src="adagrad.png" alt></p><p>​                                <strong>基于AdaGrad的最优化的更新路径</strong></p><p>​    由图可知，函数的取值高效地向着最小值移动。由于y轴方向上的梯度较大，因此刚开始变动较大，但是后面会根据这个较大的变动按比例进行调整，减小更新的步伐。因此， y轴方向上的更新程度被减弱，“之”字形的变动程度有所衰减。</p><p><strong>特点</strong></p><ol><li>前期放大梯度，加速学习，后期约束梯度</li><li>适合处理稀疏梯度</li></ol><p><strong>缺点</strong></p><p>​    中后期，分母上梯度的平方的积累将会越来越大，使gradient–&gt;0, 使得训练提前结束。</p><h1 id="五、RMSProp"><a href="#五、RMSProp" class="headerlink" title="五、RMSProp"></a>五、RMSProp</h1><p>RMSProp方法并不是将过去所有的梯度一视同仁地相加，而是逐渐地遗忘过去的梯度。</p><p><strong>数学公式</strong><br>$$<br>h \leftarrow \alpha h + (1-\alpha)\frac {\partial L}{\partial W} \cdot \frac {\partial L}{\partial W}<br>$$</p><p>$$<br>W \leftarrow W - \eta \frac {1}{\sqrt h}\frac {\partial L}{\partial W}<br>$$</p><p><strong>代码实现</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">RMSprop</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""RMSprop"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> decay_rate <span class="token operator">=</span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr        self<span class="token punctuation">.</span>decay_rate <span class="token operator">=</span> decay_rate        self<span class="token punctuation">.</span>h <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>h <span class="token keyword">is</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>h <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>val<span class="token punctuation">)</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> params<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">*=</span> self<span class="token punctuation">.</span>decay_rate            self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>decay_rate<span class="token punctuation">)</span> <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span>            params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>优点</strong></p><ol><li>由于采用了梯度平方的指数加权平均，改进了AdaGrad在深度学习中过早结束的问题</li><li>适用于处理非平稳过程，-对RNN效果较好</li></ol><h1 id="六、Adam"><a href="#六、Adam" class="headerlink" title="六、Adam"></a>六、Adam</h1><p>​    Adam (Adaptive Moment Estimation)本质上是带有动量项的RMSProp。Adam的优点主要在于参数偏置校正.</p><p>​    <img src="adam.png" alt></p><p>​    Adam会设置3个超参数。一个是学习率（论文中以α出现），另外两个是一次momentum系数$\beta_1$和二次momentum系数$\beta_2$。根据论文，标准的设定值是$\beta_1$为0.9， $\beta_2$ 为0.999。设置了这些值后，大多数情况下都能顺利运行。</p><p><strong>特点</strong></p><ol><li>结合了AdaGrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点</li><li>对内存需求较小（指数加权平均不需要存储大量的值就能平均）</li><li>为不同的参数计算不同的自适应学习率</li><li>适用于大多非凸优化 - 适用于大数据集和高维空间</li></ol><h1 id="七、不同算法比较"><a href="#七、不同算法比较" class="headerlink" title="七、不同算法比较"></a>七、不同算法比较</h1><p>​    <img src="v1.webp" alt></p><p><img src="v2.webp" alt></p><ol><li>如果数据是稀疏的，就用自适应算法, 即AdaGrad, Adadelta, RMSProp, Adam</li><li>RMSProp, Adadelta, Adam 在很多情况下的效果是相似的。</li><li>Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum，随着梯度变的稀疏，Adam 比 RMSprop 效果会好。</li><li>SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。</li></ol><h1 id="八、参考"><a href="#八、参考" class="headerlink" title="八、参考"></a>八、参考</h1><p>  《深度学习入门: 基于Python的理论与实现》</p><p>​    <a href="https://blog.csdn.net/qq_28031525/article/details/79535942" target="_blank" rel="noopener">https://blog.csdn.net/qq_28031525/article/details/79535942</a></p><p>​    <a href="https://www.cnblogs.com/guoyaohua/p/8542554.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8542554.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中with的用法</title>
      <link href="/2019/11/28/python-zhong-with-de-yong-fa/"/>
      <url>/2019/11/28/python-zhong-with-de-yong-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="一、什么是with语句"><a href="#一、什么是with语句" class="headerlink" title="一、什么是with语句"></a>一、什么是with语句</h1><p>​    对于系统资源如文件、数据库连接、socket 而言，应用程序打开这些资源并执行完业务逻辑之后，必须做的一件事就是要关闭（断开）该资源。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 操作文件的方式</span><span class="token comment" spellcheck="true"># 普通方式操作文件</span>f <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 普通方式操作文件的问题</span><span class="token comment" spellcheck="true"># 1、忘记关闭文件</span><span class="token comment" spellcheck="true"># 2、程序执行的过程中发生了异常导致关闭文件的代码没有被执行</span><span class="token comment" spellcheck="true"># 可以使用try...finally的方式解决上述问题</span><span class="token keyword">try</span><span class="token punctuation">:</span>    f <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span class="token keyword">finally</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Python提供了一种更简单的解决方案:with语句</span><span class="token comment" spellcheck="true"># 不论执行过程中是否发生异常，文件都会关闭</span><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>with 语句的语法格式</strong>:</p><pre class="line-numbers language-shell"><code class="language-shell">with 表达式 [as目标]:        代码块        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​                                </p><h1 id="二、with语句的原理"><a href="#二、with语句的原理" class="headerlink" title="二、with语句的原理"></a>二、with语句的原理</h1><ol><li><p>上下文管理器</p><p>上下文管理器是一个实现了上下文协议的对象，即在对象中定义了<code>__enter__</code>和<code>__exit__</code>方法。上下文管理器定义运行时需要建立的上下文，处理程序的进入和退出。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># open函数返回的就是一个上下文管理器对象</span>f<span class="token punctuation">.</span>__enter__   <span class="token comment" spellcheck="true"># &lt;function TextIOWrapper.__enter__></span>f<span class="token punctuation">.</span>__exit__    <span class="token comment" spellcheck="true"># &lt;function TextIOWrapper.__exit__></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>__enter__(self)</code>:该方法只接收一个self参数。当对象返回时该方法立即执行，并返回当前对象或者与运行时上下文相关的其他对象。如果有as变量（as子句是可选项），返回值将被赋给as后面的变量上。</p><p><code>__exit__(self, exception_type, exception_value, traceback)</code>:退出运行时上下文，并返回一个布尔值标示是否有需要处理的异常。如果在执行with语句体时发生异常，那退出时参数会包括异常类型、异常值、异常追踪信息，否则，3个参数都是None。返回True异常被处理，返回其他任何值，异常都会抛出。</p></li></ol><ol start="2"><li><p>自定义上下文管理器</p><p>任何实现了上下文管理器协议的对象都可以称为一个上下文管理器。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 实现一个简单的open()上下文管理</span><span class="token keyword">class</span> <span class="token class-name">myopen</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>file <span class="token operator">=</span> open<span class="token punctuation">(</span>name<span class="token punctuation">,</span> mode<span class="token punctuation">)</span>              <span class="token keyword">def</span> <span class="token function">__enter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>file    <span class="token keyword">def</span> <span class="token function">__exit__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exception_type<span class="token punctuation">,</span> exception_value<span class="token punctuation">,</span> traceback<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span class="token keyword">with</span> myopen<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># test</span>f<span class="token punctuation">.</span>closed  <span class="token comment" spellcheck="true"># True</span><span class="token comment" spellcheck="true"># 同时打开多个文件</span><span class="token keyword">with</span> myopen<span class="token punctuation">(</span><span class="token string">'test1.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f1<span class="token punctuation">,</span> myopen<span class="token punctuation">(</span><span class="token string">'test2.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f2<span class="token punctuation">,</span> myopen<span class="token punctuation">(</span><span class="token string">'test3.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f3<span class="token punctuation">:</span>    f1<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test1'</span><span class="token punctuation">)</span>    f2<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test2'</span><span class="token punctuation">)</span>    f3<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'test3'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h1 id="三、contextlib"><a href="#三、contextlib" class="headerlink" title="三、contextlib"></a>三、contextlib</h1><p>​    为了更好的辅助上下文管理，python提供了<code>contextlib</code>模块，该模块通过<code>Generator</code>实现，其中的<code>contextmanager</code>作为装饰器来提供了一种针对函数级别的上下文管理机制，可以直接使用与函数/对象而不用关心<code>__enter__</code>和<code>__exit__</code>方法的具体实现。</p><ol><li><p><code>contextmanager</code></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> contextlib <span class="token keyword">import</span> contextmanager@contextmanager<span class="token keyword">def</span> <span class="token function">myopen</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        f <span class="token operator">=</span> open<span class="token punctuation">(</span>name<span class="token punctuation">,</span> model<span class="token punctuation">)</span>        <span class="token keyword">yield</span> f    <span class="token keyword">finally</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> myopen<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># test</span>f<span class="token punctuation">.</span>closed  <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><ol start="2"><li><p><code>closing</code></p><p>文件类是支持上下文管理协议的，可以直接用with语句，还有一些对象并不支持该协议，但使用的时候又要确保正常退出，这时就可以使用closing创建上下文管理器。</p></li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> urllib <span class="token keyword">import</span> request<span class="token keyword">from</span> contextlib <span class="token keyword">import</span> closing<span class="token punctuation">,</span> contextmanager<span class="token keyword">with</span> closing<span class="token punctuation">(</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span><span class="token string">'https://www.baidu.com/'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    data <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Status:'</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>status<span class="token punctuation">,</span> f<span class="token punctuation">.</span>reason<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Data:'</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于:</span>@contextmanager<span class="token keyword">def</span> <span class="token function">closing</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">yield</span> f    <span class="token keyword">finally</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python包管理</title>
      <link href="/2019/11/28/python-bao-guan-li/"/>
      <url>/2019/11/28/python-bao-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="一、什么是包？"><a href="#一、什么是包？" class="headerlink" title="一、什么是包？"></a>一、什么是包？</h1><p>简单来说包即是目录，但和普通目录不同，它除了包含python文件以外，还包含一个<code>__init__.py</code>文件，同时它允许嵌套。</p><p>包结构如下：</p><pre class="line-numbers language-python"><code class="language-python">package<span class="token operator">/</span>__init__<span class="token punctuation">.</span>py        module1<span class="token punctuation">.</span>py            <span class="token keyword">class</span> <span class="token class-name">C1</span><span class="token punctuation">:</span><span class="token keyword">pass</span>        module2<span class="token punctuation">.</span>py            <span class="token keyword">class</span> <span class="token class-name">C2</span><span class="token punctuation">:</span><span class="token keyword">pass</span>        subpackage<span class="token operator">/</span>__init__<span class="token punctuation">.</span>py                   module1<span class="token punctuation">.</span>py                                          module2<span class="token punctuation">.</span>py                                     module3<span class="token punctuation">.</span>pymain<span class="token punctuation">.</span>py<span class="token keyword">import</span> package<span class="token keyword">import</span> package<span class="token punctuation">.</span>module1<span class="token keyword">import</span> package<span class="token punctuation">.</span>subpackage<span class="token keyword">import</span> package<span class="token punctuation">.</span>subpackage<span class="token punctuation">.</span>module1<span class="token keyword">from</span> package <span class="token keyword">import</span> module1<span class="token keyword">from</span> package <span class="token keyword">import</span> subpackage<span class="token keyword">from</span> package<span class="token punctuation">.</span>subpackage <span class="token keyword">import</span> module1<span class="token comment" spellcheck="true"># from package import module3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="二、-init-py的作用"><a href="#二、-init-py的作用" class="headerlink" title="二、__init__.py的作用"></a>二、<code>__init__.py</code>的作用</h1><ol><li><p>区别包和普通目录</p></li><li><p>可以使模块中的对象变成包可见</p><p>例如：要导入package包下module1中的类Test, 当<code>__init__.py</code>文件为空的时候需要使用完整的导入路径:<code>from package.module import Test</code>, 但如果在<code>__init__.py</code>中添加<code>from module1 import Test</code>语句，就可以直接使用<code>from package import Test</code>来导入类Test。</p></li><li><p>通过在该文件中定义<code>__all__</code>变量，控制需要导入的子包或模块。</p></li></ol><h1 id="三、-all-的作用"><a href="#三、-all-的作用" class="headerlink" title="三、__all__的作用"></a>三、<code>__all__</code>的作用</h1><p>​    <code>__all__</code>只控制<code>from xxx import *</code>的行为, 不影响<code>import</code> 和 <code>from xxx import xxxx</code>的行为</p><ol><li><p>在<code>__init__.py</code>文件中添加：</p><p>​                    <code>__all__ = [&#39;module1&#39;, &#39;subpackage&#39;]</code></p><p><code>__init__.py</code>不使用<code>__all__</code>属性，不能通过<code>from package import *</code>导入</p><p><code>__init__.py</code>使用<code>__all__</code>属性，<code>from package import *</code>只能导入<code>__all__</code>列表中的成员，但可以通过</p><p><code>import package.module2</code>和<code>from package import module2</code>导入</p></li><li><p>在普通<code>*.py</code>文件中添加：<code>__all__</code></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># from xxx import * 这种方式只能导入公有的属性，方法或类【无法导入以单下划线开头（protected）或以双下划线开头(private)的属性，方法或类】</span><span class="token comment" spellcheck="true"># from xxx import aa, bb 可以导入public,protected,private</span><span class="token comment" spellcheck="true"># import xxx   xxx.__func  可以访问public,protected,private</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>模块中不使用<code>__all__</code>属性，可以导入模块内的所有公有属性，函数和类 。</p><p>模块中使用<code>__all__</code>属性，只能导入<code>__all__</code>中定义的属性，函数和类(包括私有属性和保护属性)。</p></li></ol><h1 id="四、from-import-的问题"><a href="#四、from-import-的问题" class="headerlink" title="四、from ... import ...的问题"></a>四、<code>from ... import ...</code>的问题</h1><ol><li><p>命名空间的冲突</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># module1.py</span><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"add in module1"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># module1.py</span><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"add in module2"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># main.py</span><span class="token keyword">from</span> package<span class="token punctuation">.</span>module1 <span class="token keyword">import</span> add<span class="token keyword">from</span> package<span class="token punctuation">.</span>module2 <span class="token keyword">import</span> add<span class="token comment" spellcheck="true"># 最近导入的add,会覆盖先导入的add</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><ol start="2"><li><p>循环嵌套导入的问题</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># module1.py</span><span class="token keyword">from</span> module2 <span class="token keyword">import</span> g<span class="token keyword">def</span> <span class="token function">x</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">pass</span><span class="token comment" spellcheck="true"># module2.py</span><span class="token keyword">from</span> module1 <span class="token keyword">import</span> x<span class="token keyword">def</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">pass</span><span class="token comment" spellcheck="true"># 会抛出一个ImportError: cannot import name 'g'异常，解决方法直接使用import 语句</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pyhton高数计算库</title>
      <link href="/2019/11/25/pyhton-gao-shu-ji-suan-ku/"/>
      <url>/2019/11/25/pyhton-gao-shu-ji-suan-ku/</url>
      
        <content type="html"><![CDATA[<h1 id="math数学库"><a href="#math数学库" class="headerlink" title="math数学库"></a>math数学库</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入math库</span><span class="token keyword">import</span> math<span class="token comment" spellcheck="true"># 常用数学常量</span>math<span class="token punctuation">.</span>pi        <span class="token comment" spellcheck="true"># π</span>math<span class="token punctuation">.</span>emath<span class="token punctuation">.</span>inf    <span class="token comment" spellcheck="true"># ∞</span>math<span class="token punctuation">.</span>nan    <span class="token comment" spellcheck="true"># not a num</span><span class="token comment" spellcheck="true"># 指数/对数/开平方</span>math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># math.e**a</span>math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 自然底数 math.e</span>math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 以b为底，b**x = a</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 开平方</span><span class="token comment" spellcheck="true"># 近似值</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token number">4.1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># roud up to 5</span>math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token number">4.9</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># roud up to 4</span><span class="token comment" spellcheck="true"># 阶乘</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># a!</span><span class="token comment" spellcheck="true"># 最大公约数</span>math<span class="token punctuation">.</span>gcd<span class="token punctuation">(</span><span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 7</span><span class="token comment" spellcheck="true"># 三角函数</span>math<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>math<span class="token punctuation">.</span>pi<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 1.0</span>math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span>math<span class="token punctuation">.</span>tan<span class="token punctuation">(</span><span class="token punctuation">)</span>math<span class="token punctuation">.</span>asin<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 1.5707963267948966</span>math<span class="token punctuation">.</span>acos<span class="token punctuation">(</span><span class="token punctuation">)</span>math<span class="token punctuation">.</span>atan<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 弧度角度转换</span>math<span class="token punctuation">.</span>degrees<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 弧度转角度</span>math<span class="token punctuation">.</span>radians<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 角度转弧度</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="sympy代数运算库"><a href="#sympy代数运算库" class="headerlink" title="sympy代数运算库"></a>sympy代数运算库</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入库</span><span class="token keyword">from</span> sympy <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment" spellcheck="true"># 有理数</span>Rational<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 1/3</span><span class="token comment" spellcheck="true"># 特殊无理数</span>pi    <span class="token comment" spellcheck="true"># math.pi</span>E    <span class="token comment" spellcheck="true"># math.e</span>oo    <span class="token comment" spellcheck="true"># math.inf</span><span class="token comment" spellcheck="true"># jupyter pretty print</span>init_printing<span class="token punctuation">(</span>pretty_print<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Pretty printing mode</span>N<span class="token punctuation">(</span>pi<span class="token punctuation">)</span> <span class="token operator">=</span> pi<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 3.15..默认取前15位</span><span class="token comment" spellcheck="true"># .n() and N() are equivalent to .evalf();</span><span class="token comment" spellcheck="true"># 代数运算 用符号代替数进行运算</span>x <span class="token operator">=</span> Symbol<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 声明一个代数符号</span>x<span class="token punctuation">,</span>y <span class="token operator">=</span> symbols<span class="token punctuation">(</span><span class="token string">'x y'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 一次声明的多个代数符号</span><span class="token punctuation">(</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>  <span class="token comment" spellcheck="true"># (𝑥+𝑦)2</span><span class="token comment" spellcheck="true"># 展开和分解</span><span class="token comment" spellcheck="true"># 展开多项式</span>expand<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 𝑥2+2𝑥𝑦+𝑦2</span><span class="token comment" spellcheck="true"># 展开三角函数</span>expand<span class="token punctuation">(</span>cos<span class="token punctuation">(</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> trig<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># sin2(𝑥)sin2(𝑦)−2sin(𝑥)sin(𝑦)cos(𝑥)cos(𝑦)+cos2(𝑥)cos2(𝑦)</span><span class="token comment" spellcheck="true"># 化简</span>simplify<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">+</span>x<span class="token operator">*</span>y<span class="token punctuation">)</span><span class="token operator">/</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1+y</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="累加运算"><a href="#累加运算" class="headerlink" title="累加运算"></a>累加运算</h2><p>$$<br>\sum_{x=1}^{10} {\frac {1}{x^2 + 2x}}<br>$$</p><pre class="line-numbers language-python"><code class="language-python">expr <span class="token operator">=</span> Sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>expr <span class="token comment" spellcheck="true"># 上面公式</span>expr<span class="token punctuation">.</span>evalf<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 求值 0.662878787878788</span>expr<span class="token punctuation">.</span>doit<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 175/264</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="累积运算"><a href="#累积运算" class="headerlink" title="累积运算"></a>累积运算</h2><p>$$<br>\prod_{x=1}^{10} {\frac {1}{x^2 + 2x}}<br>$$</p><pre class="line-numbers language-python"><code class="language-python">expr <span class="token operator">=</span> Product<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>exprexpr<span class="token punctuation">.</span>doit<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 1/869100503040000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="极限"><a href="#极限" class="headerlink" title="极限"></a>极限</h2><p>$$<br>\lim_{n \to +\infty} \frac{1}{n(n+1)} \quad<br>$$</p><pre class="line-numbers language-python"><code class="language-python">n <span class="token operator">=</span> Symbol<span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">)</span>expr <span class="token operator">=</span> limit<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span>n<span class="token operator">*</span><span class="token punctuation">(</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> oo<span class="token punctuation">)</span>expr    <span class="token comment" spellcheck="true"># 0</span><span class="token comment" spellcheck="true"># 左极限和有极限</span>limit<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> dir<span class="token operator">=</span><span class="token string">'+'</span><span class="token punctuation">)</span>limit<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> dir<span class="token operator">=</span><span class="token string">'-'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><pre class="line-numbers language-python"><code class="language-python">diff<span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 2x</span>diff<span class="token punctuation">(</span>sin<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 2cos(2𝑥)</span>diff<span class="token punctuation">(</span>sin<span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token operator">+</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># diff(E**x*(x + sin(x)), x)</span><span class="token comment" spellcheck="true"># 高阶导数</span><span class="token comment" spellcheck="true"># 二阶导数</span>diff<span class="token punctuation">(</span>sin<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># −4sin(2𝑥)</span><span class="token comment" spellcheck="true"># 三阶导数</span>diff<span class="token punctuation">(</span>sin<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># −8cos(2𝑥)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="积分"><a href="#积分" class="headerlink" title="积分"></a>积分</h2><p>不指定区间<br>$$<br>\int_{-\infty}^\infty {x^2} \,{\rm dx}<br>$$</p><pre class="line-numbers language-python"><code class="language-python">integrate<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 𝑥2</span>integrate<span class="token punctuation">(</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># −cos(𝑥)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>指定区间[a, b]<br>$$<br>\int_a^b {x^2} \,{\rm dx}<br>$$</p><pre class="line-numbers language-python"><code class="language-python">integrate<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1</span>integrate<span class="token punctuation">(</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">-</span>pi<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">,</span> pi<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="解方程"><a href="#解方程" class="headerlink" title="解方程"></a>解方程</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 解一元方程</span>solve<span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">3</span><span class="token operator">*</span>x<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># [1, 2]</span><span class="token comment" spellcheck="true"># 解二元方程</span>solve<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token operator">+</span><span class="token number">5</span><span class="token operator">*</span>y<span class="token number">-2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3</span><span class="token operator">*</span>x<span class="token operator">+</span><span class="token number">6</span><span class="token operator">*</span>y<span class="token number">-15</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#{x:-3, y:1}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="代数运算"><a href="#代数运算" class="headerlink" title="代数运算"></a>代数运算</h2><pre class="line-numbers language-python"><code class="language-python">expr <span class="token operator">=</span> x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>x <span class="token operator">+</span> <span class="token number">1</span><span class="token comment" spellcheck="true"># 令x = 2</span>expr<span class="token punctuation">.</span>subs<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 9b</span><span class="token comment" spellcheck="true"># 令x=y+1</span>expr<span class="token punctuation">.</span>subs<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 2𝑦+(𝑦+1)2+3</span><span class="token comment" spellcheck="true"># 多元函数代数</span>expr <span class="token operator">=</span> x<span class="token operator">**</span><span class="token number">3</span> <span class="token operator">+</span> <span class="token number">4</span><span class="token operator">*</span>x<span class="token operator">*</span>y <span class="token operator">-</span>zexpr<span class="token punctuation">.</span>subs<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>z<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 5</span><span class="token comment" spellcheck="true"># 使用字符串</span>expr <span class="token operator">=</span> sympify<span class="token punctuation">(</span><span class="token string">"x*2 + 4*x*y"</span><span class="token punctuation">)</span>expr<span class="token punctuation">.</span>subs<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 6</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sympy <span class="token keyword">import</span> stats<span class="token comment" spellcheck="true">#创建一个6个面的筛子</span>X <span class="token operator">=</span> stats<span class="token punctuation">.</span>Die<span class="token punctuation">(</span><span class="token string">'X'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 查看某个面出现的概率</span>stats<span class="token punctuation">.</span>density<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>dict    <span class="token comment" spellcheck="true"># {1: 1/6, 2: 1/6, 3: 1/6, 4: 1/6, 5: 1/6, 6: 1/6}</span><span class="token comment" spellcheck="true"># 随机丢一次筛子</span>stats<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>X<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 4</span><span class="token comment" spellcheck="true">#     硬币</span>C <span class="token operator">=</span> stats<span class="token punctuation">.</span>Coin<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>    stats<span class="token punctuation">.</span>density<span class="token punctuation">(</span>C<span class="token punctuation">)</span><span class="token punctuation">.</span>dict    <span class="token comment" spellcheck="true"># {H: 1/2, T: 1/2}</span><span class="token comment" spellcheck="true"># 正态分布</span>Z <span class="token operator">=</span> stats<span class="token punctuation">.</span>Normal<span class="token punctuation">(</span><span class="token string">'Z'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Z>1的概率</span>stats<span class="token punctuation">.</span>P<span class="token punctuation">(</span>Z <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>evalf<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0.158655253931457</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> math </tag>
            
            <tag> sympy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络简介</title>
      <link href="/2019/11/25/shen-jing-wang-luo-jian-jie/"/>
      <url>/2019/11/25/shen-jing-wang-luo-jian-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="一、感知器"><a href="#一、感知器" class="headerlink" title="一、感知器"></a>一、感知器</h1><p>​    感知器(perceptron)是由美国学者FrankRoseblatt在1957年提出来的。为何我们现在还要学习这一很久以前就有的算法呢？因为感知机也是作为神经网络（深度学习）的起源的算法。因此，学习感知机的构造也就是学习通向神经网络和深度学习的一种重要思想。</p><h2 id="1-什么是感知器"><a href="#1-什么是感知器" class="headerlink" title="1.什么是感知器"></a>1.什么是感知器</h2><p>​    感知机接收多个输入，生成一个输出，输出只有两种1和0。</p><p>​    <img src="p1.png" alt></p><p>​                                    <strong>图1.1 有两个输入的感知机</strong></p><p>图1-1是一个接收两个输入的感知机. $x_1$、$x_2$是输入，$y$是输出，$w_1$、$w_2$是权重。图中的○称为神经元或者节点。输入被送往神经元时，会被分别乘以固定的权重$(w_1x_1,  w_2x_2)$。神经元会计算传送过来的输入的总和，只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活” 。这里将这个界限值称为阈值，用符号θ表示。<br>$$<br>y =<br>\begin{cases}<br>1, &amp; (w_1x_1 + w_2x_2) &gt; \theta \<br>0, &amp; (w_1x_1 + w_2x_2) \leq \theta<br>\end{cases}<br>$$<br>权重越大，对应该权重的信号的重要性就越高。</p><h2 id="2-逻辑运算"><a href="#2-逻辑运算" class="headerlink" title="2.逻辑运算"></a>2.逻辑运算</h2><p>使用感知器可以解决简单的逻辑运算，与门(AND), 与非门(NOT AND), 或门(OR).</p><p>​    <img src="p2.png" alt></p><p>​                                        <strong>1-2 与门真值表</strong></p><p>满足图2-2的条件的参数的选择方法有无数多个。比如，当<br>$(w_1, w_2, θ) = (0.5, 0.5, 0.7) $时，可以满足图 2-1的条件。</p><p>我们看着真值表这种“训练数据”，人工考虑（想到）了参数的值。而机器学习的课题就是将这个决定参数值的工作交由计算机自动进行。 学习是确定合适的参数的过程，而人要做的是思考感知机的构造（模型），并把训练数据交给计算机。</p><h2 id="3-偏置和权重"><a href="#3-偏置和权重" class="headerlink" title="3.偏置和权重"></a>3.偏置和权重</h2><p>$$<br>y =\begin{cases}1, &amp; (b + w_1x_1 + w_2x_2) &gt; 0 \\0, &amp; (b + w_1x_1 + w_2x_2) \leq 0\end{cases}<br>$$</p><p>令$b = -\theta$， $b$称为偏置，$w_1$和$w_2$称为权重, 但是请注意，偏置和权重$w_1$、$w_2$的作用是不一样的。具体地说， $w_1$和$w_2$是控制输入的重要性的参数，而偏置是调整神经元被激活的容易程度（输出为1的程度）的参数。有时也会将$b$、$w_1$、$w_2$这些参数统称为权重。</p><h2 id="4-单层感知机的局限性"><a href="#4-单层感知机的局限性" class="headerlink" title="4.单层感知机的局限性"></a>4.单层感知机的局限性</h2><p>单层感知机的局限性就在于它只能表示由一条直线分割的空间,无法表示用曲线分割的空间。弯曲的曲线无法用感知机表示</p><p>​    <img src="p3.png" alt></p><p>​        <strong>图1-3　○和△表示异或门的输出。可否通过一条直线作出分割○和△的空间呢？</strong></p><p>​    <img src="p4.png" alt></p><p>​                    <strong>图1-4　使用曲线可以分开○和△</strong></p><h2 id="5-多层感知机"><a href="#5-多层感知机" class="headerlink" title="5.多层感知机"></a>5.多层感知机</h2><p>​    单层感知机虽然不能表示异或，但多层感知机的叠加却可以。</p><p>​    <img src="p5.png" alt></p><p>​                        <strong>图1-5　通过组合与门、与非门、或门实现异或门</strong></p><p>​    <img src="p6.png" alt></p><p>​                    <strong>图2-6　用感知机表示异或门</strong>            </p><p>叠加了多层的感知机也称为多层感知机（multi-layered perceptron）。异或可以通过多层感知机实现。</p><p>图2-6中的感知机总共由3层构成，但是因为拥有权重的层实质上只有2层（第0层和第1层之间，第1层和第2层之间），所以称为“2层感知机”。不过，有的文献认为图2-6的感知机是由3层构成的，因而将其称为“3层感知机”。</p><h2 id="6-感知机与计算机"><a href="#6-感知机与计算机" class="headerlink" title="6.感知机与计算机"></a>6.感知机与计算机</h2><p>​    多层感知机能够进行复杂的表示，甚至可以构建计算机。那么，什么构造的感知机才能表示计算机呢？层级多深才可以构建计算机呢？</p><p>​    <strong>理论上</strong>可以说2层感知机就能构建计算机。这是因为，已有研究证明，2层感知机（严格地说是激活函数使用了非线性的sigmoid函数的感知机）可以表示任意函数。但是，使用2层感知机的构造，通过设定合适的权重来构建计算机是一件非常累人的事情。</p><p>​    实际上，在用与非门等低层的元件构建计算机的情况下，分阶段地制作所需的零件（模块）会比较自然，即先实现与门和或门，然后实现半加器和全加器，接着实现算数逻辑单元(ALU), 然后实现CPU。因此，通过感知机表示计算机时，使用叠加了多层的构造来实现是比较自然的流程。</p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>​    感知机从算法的角度来说就是单位阶跃函数+线性回归算法。</p><h1 id="二、神经网路"><a href="#二、神经网路" class="headerlink" title="二、神经网路"></a>二、神经网路</h1><h2 id="1-1-从感知器到神经网络"><a href="#1-1-从感知器到神经网络" class="headerlink" title="1.1 从感知器到神经网络"></a>1.1 从感知器到神经网络</h2><p>​    一般而言，“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数 的模型。“多层感知机”是指神经网络，即使用<code>sigmoid</code> 函数等平滑的激活函数的多层网络。</p><p>​    <img src="p7.png" alt></p><p>​    如图所示。我们把最左边的一列称为输入层，最右边的一列称为输出层，中间的一列称为中间层。中间层有时也称为隐藏层.</p><p>​    图中的网络一共由 3 层神经元构成, 但实质上只有 2层神经元有权重，因此将其称为“2层网络”。</p><h2 id="1-2-激活函数"><a href="#1-2-激活函数" class="headerlink" title="1.2 激活函数"></a>1.2 激活函数</h2><p>​    神经网络与感知机的一个最大区别是它使用了“阶跃函数”之外的其他激活函数，比如sigmoid函数。sigmoid函数相比”阶跃函数”更佳平滑.</p><p>​    阶跃函数和sigmoid函数均为非线性函数, 线性函数是一条笔直的直线，而非线性函数，顾名思义，指的是不像线性函数那样呈现出一条直线的函数。</p><p>​    激活函数一定是非线性函数，它的主要作用就是增加神经网络的非线性，因为线性函数的线性组合还是线性函数，这样的话多层神经网络就没有意义。</p><p>​    输出层的激活函数，要根据求解问题的性质决定。一般地，回归问题可以使用恒等函数，二元问题可以使用sigmoid函数，多元分类问题可以使用softmax函数。所谓恒等函数，就是按输入原样输出，对于输入的信息，不加任何改动地直接输出。</p><p>​    常见的激活函数:</p><ul><li>阶跃函数:  </li></ul><p>$$<br>h(x) =\begin{cases}1, &amp; x &gt; 0 \\0, &amp; x \leq 0\end{cases}<br>$$</p><p>​    <img src="n2.png" alt></p><ul><li>sigmoid函数(S函数)<br>$$<br>h(x) = \dfrac {1}{1+e^{-x}}<br>$$</li></ul><p>  <img src="n3.png" alt></p><ul><li>Relu函数<br>$$<br>h(x) =\begin{cases}x, &amp; x &gt; 0 \\0, &amp; x \leq 0\end{cases}<br>$$</li></ul><p>  <img src="n4.png" alt></p><ul><li>softmax函数</li></ul><p>$$<br>\sigma(x) =  \dfrac {e^{a_k}}{ \sum_{i=1}^n e^{a^i}   }<br>$$</p><p><strong>注意</strong>: softmax函数有一个缺陷就是溢出问题，softmax函数的实现中要进行指数函数的运算，但是此时指数函数的值很容易变得非常大。如，$e^{1000}$的结果会返回一个表示无穷大的inf。</p><p>改进: 先进行归一化，在求值</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1010</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">990</span><span class="token punctuation">]</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#  array([nan, nan, nan])  没有计算正确的值</span>mi <span class="token operator">=</span> np<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># 990                                 </span>ma <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">)</span>                                 nor <span class="token operator">=</span> <span class="token punctuation">(</span>a<span class="token operator">-</span>mi<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>ma<span class="token operator">-</span>mi<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 归一化 array([1. , 0.5, 0. ])   </span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>nor<span class="token punctuation">)</span><span class="token operator">/</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>nor<span class="token punctuation">)</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true"># array([0.50648039, 0.30719589, 0.18632372])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    一般而言，神经网络只把输出值最大的神经元所对应的类别作为识别结果。并且，即便使用softmax函数，输出值最大的神经元的位置也不会变。因此，神经网络在进行分类时，输出层的softmax函数可以省略。在实际的问题中，由于指数函数的运算需要一定的计算机运算量，因此<strong>输出层的softmax函数一般会被省略</strong></p><p>​    求解机器学习问题的步骤可以分为“学习” A 和“推理”两个阶段。首先， 在学习阶段进行模型的学习 ，然后，在推理阶段，用学到的模型对未知的数据进行推理（分类）。如前所述，推理阶段一般会省略输出层的 softmax 函数。在输出层使用 softmax 函数是因为它和<br>神经网络的学习有关系</p><h2 id="1-3-3层神经网络"><a href="#1-3-3层神经网络" class="headerlink" title="1.3 3层神经网络"></a>1.3 3层神经网络</h2><p>​    <img src="n7.png" alt></p><p>3层神经网络：输入层（第0层）有2个神经元，第1个隐藏层（第1层）有3个神经元，第2个隐藏层（第2层）有2个神经元，输出层（第3层）有2个神经元</p><p><img src="n6.png" alt></p><p>​                                图２－６权重的符号</p><p>请注意，偏置的右下角的索引号只有一个。这是因为前一层的偏置神经元（神经元“1”）只有一个，索引表示的是后一层神经元的索引。</p><p>数学公式表示$a_1^{(1)}$<br>$$<br>a_1^{(1)} = a_{11}^{(1)}x1 + w_{12}^{(1)}x2 + b_1^{(1)}<br>$$<br>矩阵$W^{(1)}$表示第１层的权重：<br>$$<br>W^{(1)} = \begin{pmatrix}w_{11}^{(1)} &amp; w_{12}^{(1)} &amp; w_{13}^{(1)}\\\\w_{12}^{(1)} &amp;w_{22}^{(1)} &amp;w_{32}^{(1)}\end{pmatrix}<br>$$<br>向量$B^{(1)}$表示第一层的偏置:<br>$$<br>\begin{pmatrix} b_1^{(1)} &amp; b_2^{(1)} &amp; b_3^{(1)}\\ \end{pmatrix} \quad<br>$$</p><p>$$<br>A^{(1)} = \begin{pmatrix} a_1^{(1)} &amp; a_2^{(1)} &amp; a_3^{(1)}\\ \end{pmatrix} \quad<br>$$</p><p>$$<br>X^{(1)} = \begin{pmatrix} x_1 &amp; x_2\\ \end{pmatrix} \quad<br>$$</p><p>第１层的加权和表示:<br>$$<br>A^{(1)} = XW^{(1)} + B^{(1)}<br>$$</p><h1 id="三、神经网络的学习"><a href="#三、神经网络的学习" class="headerlink" title="三、神经网络的学习"></a>三、神经网络的学习</h1><p>​    神经网络的学习就是从训练数据学习权重参数，然后使用刚才学习到的参数对输入数据进行预测。</p><p>​    神经网络学习的策略是首先对输入数据进行前向传播(forward propagation)过程得到输出，然后计算输出与真实值之间的差别，最后通过反向传播跟新权重参数，重复这一过程直到权重参数没有更新，此时损失函数达到最小。</p><p>​    计算输出与真实值之间的差别通过损失函数计算。反向传播需要用到梯度下降算法实现。</p><h2 id="1-损失函数"><a href="#1-损失函数" class="headerlink" title="1.损失函数"></a>1.损失函数</h2><p>​    损失函数是表示神经网络性能的指标。神经网络通过减小损失函数，寻找最优权重参数。常用的误差函数有均方误差和交叉熵误差等。</p><ul><li>均方误差(mean squared error MSE)</li></ul><p>$$<br>E = \frac {1}{2} \sum_{k}({y_k - t_k})^2<br>$$</p><p>​    $y_k$表示神经网络的输出，$t_k$表示目标数据，k表示输出数据的维度，比如　手写数字识别的输出数据的维度是10 (0-9)。</p><ul><li>交叉熵误差(cross entropy error)<br>$$<br>E = - \sum_{k}t_k\log y_k<br>$$<br>上式是一条数据的误差，如果批量计算多条数据则函数为:<br>$$<br>E = - \frac{1}{N}\sum_{N}\sum_{k}t_{nk}\log y_{nk}<br>$$<br>假设数据有N个， $t_{nk}$表示第n个数据的第k个元素的值（$y_{nk}$是神<br>经网络的输出， $t_{nk}$是目标数据）, 不过最后还要除以N, 通过这样的<br>平均化，可以获得和训练数据的数量无关的统一指标。</li></ul><h2 id="2-梯度下降"><a href="#2-梯度下降" class="headerlink" title="2.梯度下降"></a>2.梯度下降</h2><p>​    梯度是导数对多元函数的推广，它是多元函数对各个变量偏导形成的向量。多元函数的梯度定义为:<br>$$<br>\triangledown(x) = \begin{pmatrix} \frac{\partial f}{\partial x_1}, &amp; …, &amp; \frac{\partial f}{\partial x_n}\\  \end{pmatrix}^{T} \quad<br>$$<br>　其中$\triangledown$称为梯度算子，它作用与一个多元函数，得到一个向量。梯度是一个向量，即有大小又有方向，大小为该点的变化率，方向是该点增加最快的方向，-$\triangledown$(x)就为减小最快的方向。所以只要沿着梯度的反方向就可能达到函数的驻点，可能是局部极小值，全局极小值或鞍点。</p><p>​    在梯度下降法中，函数的取值从当前位置沿着梯度反方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度反方向前进，如此反复，不断地沿梯度方向前进。像这样，通过不断地沿梯度反方向前进，逐渐减小函数值的过程就是梯度下降法（gradient descent method）。</p><p>​    梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。寻找最小值的梯度法称为梯度下降法（gradient descent method），寻找最大值的梯度法称为梯度上升法（gradient ascent method）。但是通过反转损失函数的符号，求最小值的问题和求最大值的问题会变成相同的问题。</p><p>数学公式来表示梯度下降方法:<br>$$<br>x_0 = x_0 - \eta \frac {\partial f}{\partial x_0}<br>$$</p><p>$$<br>x_1 = x_1 - \eta \frac {\partial f}{\partial x_1}<br>$$</p><p>$\eta$是学习率，表示根据梯度值变化的幅度，x在神经网络中代表权重.</p><p>​    控制梯度下降的幅度</p><p>​    0.1    0.01    0.001    ….</p><p>​    如果学习率太大，误差会逐步增大</p><p>​    如果学习率较大，误差会来回震荡</p><p>​    如果学习率太小， 误差下降缓慢</p><p>​    <img src="n8.png" alt></p><p>​                    图　$f(x_0, x_1) = x_0^2 + x_1^2$的梯度下降更新过程:虚线是函数的等高线</p><p>神经网络的学习分成下面4个步骤:<br><strong>步骤1（ mini-batch）</strong><br>    从训练数据中选出一部分数据，这部分数据称为mini-batch。我们的目标是减小损失函数的值。<br><strong>步骤2（计算梯度）</strong><br>    为了减小损失函数的值，需要求出各个权重参数的梯度。<br><strong>步骤3（更新参数）</strong><br>    将权重参数沿梯度方向进行微小更新。        </p><p><strong>步骤4（重复）</strong><br>    重复步骤1、步骤2、步骤3, 直到梯度为０或接近０．</p><p>​        </p><h2 id="3-误差反向传播"><a href="#3-误差反向传播" class="headerlink" title="3.误差反向传播"></a>3.误差反向传播</h2><ol><li><p>计算图</p><p>小明在超市买了2个苹果、 3个橘子。其中，苹果每个100日元，<br>橘子每个150日元。消费税是10%，请计算支付金额。</p><p><img src="b1.png" alt></p><p>​                        <strong>计算图的求解过程</strong></p><p>​    在计算图上，从左向右进行计算是一种正方向的传播, 简称为<strong>正向传播</strong>(forward propagation)。同理，反方向的计算，就是<strong>反向传播</strong>(backward propagation)。</p><p>​    计算图的特征是可以通过传递“局部计算”获得最终结果。局部计算是指，无论全局发生了什么，都能只根据与自己相关的信息输出接下来的结果。</p></li></ol><p>   <img src="b2.png" alt></p><p>   ​    计算图的优点是，可以通过正向传播和反向传播高效地计算各个变量的导数值. 从上图可以看到，如果消费税和苹果的价格增加相同的值，则消费税将对最终价格产生200倍大小的影响，苹果的价格将产生2.2倍大小的影响。不过，因为这个例子中消费税和苹果的价格的量纲不同，所以才形成了这样的结果（消费税的1是100%，苹果的价格的1是1元）。</p><ol start="2"><li><p>链式法则</p><p>反向传播将局部导数向正方向的反方向（从右到左）传递，传递这个局部导数的原理，是基于<strong>链式法则</strong>的。</p><p><img src="b3.png" alt></p><p><strong>图b3 计算图的反向传播：沿着与正方向相反的方向，乘上局部导数</strong></p><p>如图所示，反向传播的计算顺序是，将信号$E$乘以节点的局部导数<br>$(\frac {\partial y}{\partial x})$，然后将结果传递给下一个节点。这里所说的局部导数是指正向传播中y = f(x)的导数，也就是y关于x的导数$(\frac {\partial y}{\partial x})$。比如，假设$y = f(x) = x2$，则局部导数为 $(\frac {\partial y}{\partial x})$= $2x$。把这个局部导数乘以上游传过来的值（本例中为E），然后传递给前面的节点。</p></li></ol><p>   <img src="b4.png" alt></p><p>   根据链式法则，$\frac {\partial z}{\partial z} \frac {\partial z}{\partial t} \frac {\partial t}{\partial x} = \frac {\partial z}{\partial t} \frac {\partial t}{\partial x} = \frac {\partial z}{\partial x}$成立，对应“z关于x的导数”。也就是说，反向传播是基于链式法则的</p><ol start="4"><li><p>激活函数的反向传播</p><ul><li><p>Relu激活函数<br>$$<br>h^{‘}(x) =\begin{cases}1, &amp; x &gt; 0 \\0, &amp; x \leq 0\end{cases}<br>$$<br>如果正向传播时的输入x大于0，则反向传播会将上游的值原封不动地传给下游。反过来，如果正向传播时的x小于等于0，则反向传播中传给下游的信号将停在此处。</p><p>Relu 层的作用就像电路中的开关一样。正向传播时，有电流通过的话，就将开关设为ON；没有电流通过的话，就将开关设为OFF。反向传播时，开关为ON的话，电流会直接通过；开关为OFF的话，则不会有电流通过。</p></li><li><p>Sigmoid激活函数<br>$$<br>h^{‘}(y) = y(1-y)<br>$$</p></li></ul></li></ol><pre><code> ```python class Sigmoid:     def __init__(self):         self.out = None     # 保存当前层的输出     def forward(self, x):         &quot;&quot;&quot;         前向传播         :param x:          :return:          &quot;&quot;&quot;         out = sigmoid(x)         self.out = out         return out     def backward(self, dout):         &quot;&quot;&quot;         反向传播         :param dout:          :return:          &quot;&quot;&quot;         dx = dout * (1.0 - self.out) * self.out         return dx ```</code></pre><ol start="5"><li><p>矩阵运算<br>$$<br>X \cdot W = Y<br>$$</p><p>$$<br>\frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} \cdot W^T<br>$$</p><p>$$<br>\frac{\partial L}{\partial W} = X^T \cdot \frac{\partial L}{\partial Y}<br>$$</p></li></ol><p>   <img src="b6.png" alt></p><p>   需要注意各个变量的形状</p><ol start="6"><li><p>Softmax-with-Loss层</p><p><img src="b7.png" alt></p><p>Softmax层将输入（a1, a2, a3）正规化，输出（y1,y2, y3）。 Cross Entropy Error层接收Softmax的输出（y1, y2, y3）和目标值（t1,t2, t3），从这些数据中输出损失L。</p><p>Softmax反向传播的梯度为(y1 - t1,  y2 - t2, y3 - t3).</p></li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><p>通过使用计算图，可以直观地把握计算过程。<br>• 计算图的节点是由局部计算构成的。局部计算构成全局计算。<br>• 计算图的正向传播进行一般的计算。通过计算图的反向传播，可以<br>计算各个节点的导数。<br>• 通过将神经网络的组成元素实现为层，可以高效地计算梯度（反向传<br>播法）。<br>• 通过比较数值微分和误差反向传播法的结果，可以确认误差反向传<br>播法的实现是否正确（梯度确认）</p><h1 id="四、参考"><a href="#四、参考" class="headerlink" title="四、参考"></a>四、参考</h1><p>《深度学习入门: 基于Python的理论与实现》</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> ML </tag>
            
            <tag> ANN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习概述</title>
      <link href="/2019/11/24/ji-qi-xue-xi-gai-shu/"/>
      <url>/2019/11/24/ji-qi-xue-xi-gai-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="一、人工智能"><a href="#一、人工智能" class="headerlink" title="一、人工智能"></a>一、人工智能</h1><ol><li><p>什么是人工智能</p><p>​        <img src="3.jpg" alt="3"></p><p>​        人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。<br>​        人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。</p></li><li><p>强人工智能和弱人工智能</p><p>​        早在1956年夏天那次会议，人工智能的先驱们就梦想着用当时刚刚出现的计算机来构造复杂的、拥有与人类智慧同样本质特性的机器。这就是我们现在所说的“强人工智能”（General AI）。这个无所不能的机器，它有着我们所有的感知（甚至比人更多），我们所有的理性，可以像我们一样思考。<br>​        人们在电影里也总是看到这样的机器：友好的，像星球大战中的C-3PO；邪恶的，如终结者。强人工智能现在还只存在于电影和科幻小说中，原因不难理解，我们还没法实现它们，至少目前还不行。<br>​        我们目前能实现的，一般被称为“弱人工智能”（Narrow AI）。弱人工智能是能够与人一样，甚至比人更好地执行特定任务的技术。例如，图像分类；或者人脸识别。</p></li><li><p>人工智能，机器学习和深度学习的关系</p><p><img src="1.png" alt></p></li></ol><p>   机器学习是人工智能的一种实现方式，也是最重要的实现方式。目前机器学习的方法被大量的应用解决人工智能的问题。</p><p>   深度学习是机器学习现在比较火的一个方向，其本身是神经网络算法的衍生，在图像、语音等富媒体的分类和识别上取得了非常好的效果。</p><p>   总的来说，深度学习是机器学习的一个子集，机器学习是人工智能的一个子集。</p><h1 id="二、机器学习"><a href="#二、机器学习" class="headerlink" title="二、机器学习"></a>二、机器学习</h1><h2 id="机器学习的概念"><a href="#机器学习的概念" class="headerlink" title="机器学习的概念"></a>机器学习的概念</h2><ol><li><p>什么是机器学习</p><p>机器学习就是机器像人类一样学习，人能从过去的经验中学习，对于机器来说过去的经验就是记录的数据。机器理解大量的数据然后归纳出模型来对数据进行预测和分析。</p><p><img src="11.png" alt></p></li></ol><ol start="2"><li><p>机器学习的对象</p><p>机器学习的对象是数据(data), 它从数据出发，提取数据的特征，抽取数据的模型，发现数据的知识，又回到对数据的分析与预测中去。</p><p>作为机器学习的对象，数据包括各种数字、文字、图像、音频、视频数据以及它们的组合。</p></li></ol><ol start="3"><li><p>机器学习的目的</p><p>机器学习用于对数据进行预测和分析，特别是对未知新数据进行预测和分析。对数据的预测可以让计算机更加智能化；对数据的分析可以让人们获取新的知识。</p><p>对数据的预测和分析是通过构建模型实现的。机器学习总的目标就是考虑学习什么样的模型和如何学习模型，已使模型对数据进行准确的预测和分析，同时也要尽可能地提升学习的效率。</p></li></ol><ol start="4"><li><p>机器学习的分类</p><p>机器学习由监督学习、非监督学习、半监督学习和强化学习等组成。</p><p><img src="6.jpg" alt></p><p>监督学习，非监督学习，半监督学习的区别是训练数据是否有标记。</p></li></ol><ol start="5"><li><p>机器学习的应用场景</p><p><img src="5.jpg" alt></p></li></ol><h2 id="机器学习三要素"><a href="#机器学习三要素" class="headerlink" title="机器学习三要素"></a>机器学习三要素</h2><p>​        机器学习的方法由模型，策略，算法构成。</p><ol><li><p>模型</p><p>假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，这个函数的集合就称为假设空间。</p><p>模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有可能的概率分布或决策函数。</p><p>例如：线性回归算法，它的模型就是一个线性函数，即</p><p>$$<br>f(x) = w_1x_1 + w_2x_2 + … + w_nx_n + b<br>$$<br>一般用向量形式写成   $f(x) = w^Tx +b$, 其中$w = (w_1, w_2, …, w_3)$.</p><p>$w$和$d$确定之后，模型就确定了。</p><p>根据$w$和$b$的所有取值所组成的集合就是线性回归算法的假设空间。</p></li><li><p>策略</p><p>应用某个评估指标, 从假设空间中选择一个最优的模型。</p><p>对于给定的输入$X$, 模型$f(X)$给出相应的输出$Y$, 这个输出的预测值$f(X)$与真实值$Y$可能一致也可能不一致，用一个损失函数(loss function)或代价函数(cost function)来度量预测错误的程度。记作$L(Y, f(X))$</p><p>机器学习中常用的损失函数有以下几种:</p><p>(1) 0-1损失函数(0-1 loss function)<br>$$<br>L(Y,f(X)) =<br>\begin{cases}<br>0, &amp; \text{Y = f(X)}  \<br>1, &amp; \text{Y $\neq$ f(X)}<br>\end{cases}<br>$$</p><p>(2) 平方损失函数(quadratic loss function)<br>$$<br>L(Y, f(X)) = (Y - f(X))^2<br>$$<br>(3) 绝对损失函数<br>$$<br>L(Y, f(X)) = |Y - f(X)|<br>$$<br>(4) Huber损失—-平滑绝对误差<br>$$<br>L_\delta(Y,f(X)) =<br>\begin{cases}<br>{\frac 12}(y-f(x))^2, &amp; for|y-f(x)|\le \delta  \<br>\delta|y-f(x)| - {\frac 12}{\delta}^2, &amp; \text{otherwise}<br>\end{cases}<br>$$</p><p>(5) 对数损失函数(logarithmic loss function)<br>$$<br>L(Y, P(Y|X)) = -logP(Y|X)<br>$$<br>损失函数值越小，模型就越好。<strong>损失函数值最小的模型就是最优模型</strong>。</p></li></ol><p>   举例: 线性回归, $$f(x) = w_1x_1 + w_2x_2 + … + w_nx_n + b$$ , 均方误差为<br>   $$<br>   E(w, b) = {\frac 1n}\sum_{i=1}^n (f(x_i) - Y)^2<br>   $$<br>   均方误差的几何意义就是欧几里得距离。</p><p>   <img src="12.png" alt></p><p>   <img src="14.png" alt></p><ol start="3"><li><p>算法</p><p>算法是指学习模型的具体计算方法。</p><p>机器学习常用优化算法:</p><p>(1) 梯度下降</p><p>​    随机梯度下降(<code>Stochastic Gradient Descent, SGD</code>)</p><p>​    批量梯度下降(<code>Batch Gradient Descent, BGD</code>)</p><p>​    小批量梯度下降(<code>Mini-batch Gradient Descent, MBGD</code>)</p><p>(2) 梯度下降的变体</p><p>​    <code>Momentum</code>、<code>Adagrad</code>、<code>Adadelta</code>、<code>RMSprop</code>、<code>Adam</code></p><p>(3) 牛顿法和拟牛顿法</p></li></ol><p>​        举例：线性回归的优化算法可以使用梯度下降或最小二乘法</p><p>​        在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线的欧式距离之后最小</p><p>​        求解$w$和$b$使$E(w, b) = \sum_{i=1}^n(y_i - wx_i -b)$最小化，可以将$E(w, b)$分别对$w$和$b$求导，等于0，可以得到$w$和$b$的值。</p><h2 id="机器学习的训练步骤"><a href="#机器学习的训练步骤" class="headerlink" title="机器学习的训练步骤"></a>机器学习的训练步骤</h2><h3 id="1-明确问题和目标"><a href="#1-明确问题和目标" class="headerlink" title="1. 明确问题和目标"></a>1. 明确问题和目标</h3><p>​    需要解决什么问题，达到什么目标</p><h3 id="2-确定输入，收集数据"><a href="#2-确定输入，收集数据" class="headerlink" title="2.确定输入，收集数据"></a>2.确定输入，收集数据</h3><p>​    通过多种途径得到一个有限的训练数据的集合</p><p>​    <a href="https://www.kaggle.com/datasets" target="_blank" rel="noopener">Kaggle数据集</a></p><p>​    <a href="https://registry.opendata.aws" target="_blank" rel="noopener">亚马逊数据集</a></p><p>​    <a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="noopener">UCI机器学习库</a></p><p>​    <a href="https://toolbox.google.com/datasetsearch" target="_blank" rel="noopener">谷歌的数据集搜素引擎</a></p><p>​    <a href="https://msropendata.com/" target="_blank" rel="noopener">微软数据集</a></p><p>​    <a href="https://github.com/awesomedata/awesome-public-datasets" target="_blank" rel="noopener">Awesome公共数据集</a></p><p>​    <a href="https://www.visualdata.io/" target="_blank" rel="noopener">计算机视觉数据集</a></p><p>​    <a href="http://image-net.org/" target="_blank" rel="noopener">ImageNet</a></p><p>​    <a href="http://cocodataset.org/" target="_blank" rel="noopener">MS COCO</a></p><h3 id="3-确定输出，选择算法"><a href="#3-确定输出，选择算法" class="headerlink" title="3.确定输出，选择算法"></a>3.确定输出，选择算法</h3><p>​    根据输入输出数据的类型决定使用的算法类型，分类还是回归？</p><p>​    输入变量与输出变量均为连续变量的预测问题称为回归问题；</p><p>​    输出变量为有限个离散变量的预测问题称为分类问题；</p><p>​    在对应的算法类型中选择一个或多个算法。</p><h3 id="4-特征工程"><a href="#4-特征工程" class="headerlink" title="4.特征工程"></a>4.特征工程</h3><ul><li><p>数据预处理</p><ul><li>缺失数据—&gt; 删除 和 填充 (平均数，众数)</li><li>处理特征数据—&gt; 正规化 (归一化，正则化，白化)</li><li>处理类别数据—&gt;独热编码</li><li>数据集划分—&gt;训练、验证、测试</li></ul></li><li><p>数据降维</p><ul><li><p>特征选择</p><ul><li>使用L1正则化进行数据稀疏化</li><li>序列特征选择算法  SBS</li><li>通过随机森林判定特征的重要性</li></ul></li><li><p>特征提取 (将特征压缩到一个低维空间，而不是像特征选择那样完全剔除不相关的特征)</p><ul><li>PCA  主成分分析</li><li>线性判别    </li></ul></li></ul></li></ul><h3 id="5-建立模型"><a href="#5-建立模型" class="headerlink" title="5. 建立模型"></a>5. 建立模型</h3><ul><li><p>模型空间</p></li><li><p>损失函数</p></li><li><p>优化算法</p></li><li><p>评估标准</p></li></ul><ol><li><p>模型空间</p><p>确定了算法也就确定了模型空间，模型空间包含了算法的所有可能</p></li><li><p>损失函数</p><p>根据具体的算法和输出决定损坏函数</p></li><li><p>优化算法</p><p>选择优化算法</p></li><li><p>评估指标:</p></li></ol><p><img src="7.png" alt></p><ul><li><p>分类算法</p><ul><li>准确率</li><li>精确率和召回率(查准率和查全率)</li><li>ROC和AUC</li><li>$F_1$和$F_{\beta}$</li></ul></li><li><p>回归算法</p><ul><li><p>平均绝对误差</p></li><li><p>均方误差</p></li><li><p>R2分数</p></li></ul></li></ul><h3 id="6-确定最优模型"><a href="#6-确定最优模型" class="headerlink" title="6.确定最优模型"></a>6.确定最优模型</h3><p>​    不断重复<strong>训练模型/评估模型/选择模型</strong>的步骤指导选择最优的模型</p><ul><li><p>模型选择数据集划分:</p><p>​        训练集训练模型</p><p>​        验证集评估模型</p><p>​        测试集测试模型</p><p>​        <img src="13.png" alt></p></li><li><p>使用k折交叉验证评估模型性能</p><ul><li>holdout方法</li><li>k折交叉验证</li></ul><p>通常情况下，我们将k折交叉验证用于模型的调优，也就是找到使得模型泛化性能最优的超参值。一旦找到了满意的超参值，我们就可<br>以在全部的训练数据上重新训练模型，并使用独立的测试数据集对模型性能做出最终评价。 </p></li><li><p>通过学习及验证曲线来调试算法</p><ul><li>使用学习曲线判定偏差和方差问题</li><li>使用验证曲线判定过拟合与欠拟合</li></ul></li><li><p>使用网格搜索调优机器学习模型</p><ul><li>使用网格搜索调优超参数</li><li>通过嵌套交叉验证选择模型</li><li>网格搜索（grid search），它通过寻找最优的超参值的组合以进一步提高模型的性能。 </li></ul></li></ul><h3 id="7-应用实际问题"><a href="#7-应用实际问题" class="headerlink" title="7.应用实际问题"></a>7.应用实际问题</h3><p>​    利用学习的最优模型对新数据进行预测或分析</p><h1 id="三、参考"><a href="#三、参考" class="headerlink" title="三、参考"></a>三、参考</h1><p>​    《统计学习方法》李航</p><p>​     《Python机器学习》[美] [塞巴斯蒂安·拉施卡]著  高明 徐莹 陶虎成译</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> AI </tag>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法之树</title>
      <link href="/2019/11/23/shu-ju-jie-gou-yu-suan-fa-zhi-shu/"/>
      <url>/2019/11/23/shu-ju-jie-gou-yu-suan-fa-zhi-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="一、树"><a href="#一、树" class="headerlink" title="一、树"></a>一、树</h1><h2 id="树的定义"><a href="#树的定义" class="headerlink" title="树的定义"></a>树的定义</h2><p>树(Tree)是n(n&gt;=0)个结点的有限集。当n=0时成为空树，在任意一颗非空树中：</p><ul><li>有且仅有一个特定的称为根(Root)的结点;</li><li>当n&gt;1时，其余节点可分为m(m&gt;0)个<strong>互不相交</strong>的有限集T1、T2、。。。、Tm, 其中每一个集合本身又是一棵树，并且称为根的子树(SubTree)。</li></ul><h2 id="结点的分类"><a href="#结点的分类" class="headerlink" title="结点的分类"></a>结点的分类</h2><p>结点拥有的子树称为结点的度(Degree), 树的度取树内各结点的度的最大值。</p><ul><li>度为0的结点称为叶结点(Leaf)或终端结点；</li><li>度不为0的点称为分支结点或非终端结点，除根结点外，分支结点也称为内部结点。</li></ul><h2 id="结点间的关系"><a href="#结点间的关系" class="headerlink" title="结点间的关系"></a>结点间的关系</h2><ul><li>结点的子树的根称为结点的孩子(Child), 相应的，该结点称为孩子的双亲(Parent), 同一双亲的孩子之间互称为兄弟(Sibling)。</li><li>结点的祖先是从根到该结点所经过分支上的所有结点。</li></ul><h2 id="结点的层次"><a href="#结点的层次" class="headerlink" title="结点的层次"></a>结点的层次</h2><ul><li>结点的层次(Level)从根开始，根为第一层，根的孩子为第二层。</li><li>其双亲在同一层的结点互为堂兄弟。</li><li>树中结点最大层称为树的深度(Depth)或者高度。</li></ul><h2 id="有序树和森林"><a href="#有序树和森林" class="headerlink" title="有序树和森林"></a>有序树和森林</h2><ul><li>如果将树中结点的各个子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。</li><li>森林(Forest)是m(m&gt;=0)棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。</li></ul><h2 id="树的存储结构"><a href="#树的存储结构" class="headerlink" title="树的存储结构"></a>树的存储结构</h2><h3 id="1-双亲表示法"><a href="#1-双亲表示法" class="headerlink" title="1.双亲表示法"></a>1.双亲表示法</h3><ul><li><p>双亲表示法，言外之意就是以双亲作为索引的关键词的一种存储方式。</p></li><li><p>我们假设以一组连续空间存储树的结点，同时在每个结点中，附设一个指示双亲结点在数组中位置的元素。</p></li><li><p>也就是说，每个结点除了知道自己是谁，还知道它的双亲在哪里。</p></li><li><p>那么我们可以做如下定义:</p><pre class="line-numbers language-c++"><code class="language-c++">// 树的双亲表示法结构定义#define MAX_TREE_SIZE 100typedef int ElemType;typedef struct PTNode{    ElemType data; // 结点数据    int parent;     // 双亲位置} PTNode;typedef struct{    PTNode nodes[MAX_TREE_SIZE];    int r;        // 根的位置    int n;        // 结点数目} PTree;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="parents.png" alt></p></li><li><p>这样的存储结构，我们可以根据某结点的parent指针找到它的双亲结点，所用的时间复杂度是O(1), 索引到parent的值为-1时，表示找到了树结点的根。</p></li><li><p>可是，如果我们要知道某结点的孩子是什么？那么不好意思，请遍历整个树结构。</p></li><li><p>改进一些也很简单，只需要在每个结点中添加孩子的索引</p></li></ul><h3 id="2-孩子表示法"><a href="#2-孩子表示法" class="headerlink" title="2.孩子表示法"></a>2.孩子表示法</h3><ul><li><p>方案一：根据树的度，声明足够空间存放子树的结点。缺点十分明显，就是造成了浪费！</p><p><img src="childs01.png" alt></p></li><li><p>方案二：根据每个结点的度申请空间存放子树结点。</p><p><img src="childs02.png" alt></p></li><li><p>方案三:  数组和链表结合</p><p><img src="childs03.png" alt></p></li></ul><h3 id="3-双亲孩子表示法"><a href="#3-双亲孩子表示法" class="headerlink" title="3.双亲孩子表示法"></a>3.双亲孩子表示法</h3><p>​    前两种方案结合</p><p>​    <img src="parchild.png" alt></p><pre class="line-numbers language-c++"><code class="language-c++">#define MAX_TREE_SIZE 100// 孩子节点typedef struct CTNode{    int child;  // 孩子结点下标    struct CTNode *next; // 指向下一个孩子的指针} *ChildPtr;// 表头结构typedef struct{    ElemType data;  // 存放在树中的结点的数据    int parent;        // 存放双亲的下标    ChildPtr firstchild; // 指向第一个孩子的指针} CTBox;// 树结构typedef struct{    CTBox nodes[MAX_TREE_SIZE]; // 结点数组    int r;        // 根的位置    int n;        // 结点数目}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="二、二叉树"><a href="#二、二叉树" class="headerlink" title="二、二叉树"></a>二、二叉树</h1><h2 id="二叉树的定义"><a href="#二叉树的定义" class="headerlink" title="二叉树的定义"></a>二叉树的定义</h2><ul><li>二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）</li><li>左子树和右子树是有顺序的，次序不能颠倒。</li><li>即是树中某结点只有一颗子树，也要区分它是左子树还是右子树。</li></ul><h2 id="二叉树的五种基本形态"><a href="#二叉树的五种基本形态" class="headerlink" title="二叉树的五种基本形态"></a>二叉树的五种基本形态</h2><ul><li><p>空二叉树</p></li><li><p>只有一个根结点</p></li><li><p>根结点只有左子树</p></li><li><p>根结点只有右子树</p></li><li><p>根节点即有左子树又有右子树</p><p><img src="binarytree.png" alt></p></li></ul><h2 id="特殊二叉树"><a href="#特殊二叉树" class="headerlink" title="特殊二叉树"></a>特殊二叉树</h2><ul><li><p>斜树</p></li><li><p>满二叉树</p><ul><li><p>叶子只能出现在最下一层</p></li><li><p>非叶子结点的度都是2</p></li><li><p>在同样深度的二叉树中，满二叉树的结点个数一定是最多的，同时叶子也是最多的。</p><p><img src="%E6%BB%A1%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt></p></li></ul></li><li><p>完全二叉树</p><p>若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。</p><ul><li>叶子结点只能出现在最下两层</li><li>最下层的叶子一定集中在左部连续位置。</li><li>倒数第二层，若有叶子结点，一定都在右部连续位置。</li><li>如果结点度为1，则该结点只有左孩子</li><li>同样结点树的二叉树，完全二叉树的深度是最小的。</li></ul><p><img src="%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt></p></li></ul><h2 id="二叉树的性质"><a href="#二叉树的性质" class="headerlink" title="二叉树的性质"></a>二叉树的性质</h2><p><strong>性质1:</strong> 在二叉树的第i层上至多有2^(i-1)个结点（i&gt;0）<br><strong>性质2:</strong> 深度为k的二叉树至多有2^k - 1个结点（k&gt;0）<br><strong>性质3:</strong> 对于任意一棵二叉树，如果其叶结点数为N0，而度数为2的结点总数为N2，则N0=N2+1;<br><strong>性质4:</strong>具有n个结点的完全二叉树的深度必为 log2(n+1)<br><strong>性质5:</strong>对完全二叉树，若从上至下、从左至右编号，则编号为i 的结点，其左孩子编号必为2i，其右孩子编号必为2i＋1；其双亲的编号必为i/2（i＝1 时为根,除外）</p><h1 id="三、动态查找树"><a href="#三、动态查找树" class="headerlink" title="三、动态查找树"></a>三、动态查找树</h1><h2 id="一）二叉查找树"><a href="#一）二叉查找树" class="headerlink" title="一）二叉查找树"></a>一）二叉查找树</h2><h2 id="二）平衡二叉树-AVL树"><a href="#二）平衡二叉树-AVL树" class="headerlink" title="二）平衡二叉树(AVL树)"></a>二）平衡二叉树(AVL树)</h2><h2 id="三）红黑树"><a href="#三）红黑树" class="headerlink" title="三）红黑树"></a>三）红黑树</h2><h1 id="四、多路查找树"><a href="#四、多路查找树" class="headerlink" title="四、多路查找树"></a>四、多路查找树</h1><h2 id="一）B树"><a href="#一）B树" class="headerlink" title="一）B树"></a>一）B树</h2><h2 id="二）B-树"><a href="#二）B-树" class="headerlink" title="二）B+树"></a>二）B+树</h2><h2 id="三）B-树"><a href="#三）B-树" class="headerlink" title="三）B*树"></a>三）B*树</h2><h2 id="四）R树"><a href="#四）R树" class="headerlink" title="四）R树"></a>四）R树</h2><h1 id="五、决策树"><a href="#五、决策树" class="headerlink" title="五、决策树"></a>五、决策树</h1><h1 id="六-、LeetCode关于树的题目"><a href="#六-、LeetCode关于树的题目" class="headerlink" title="六 、LeetCode关于树的题目"></a>六 、<code>LeetCode</code>关于树的题目</h1>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tree </tag>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMake用法总结</title>
      <link href="/2019/11/18/cmake-yong-fa-zong-jie/"/>
      <url>/2019/11/18/cmake-yong-fa-zong-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h1 id="一、CMake的作用"><a href="#一、CMake的作用" class="headerlink" title="一、CMake的作用"></a>一、<code>CMake</code>的作用</h1><p>大家都知道, 源文件的编译步骤为:</p><ul><li>预处理: 宏定义展开, 头文件展开, 条件编译</li><li>编译: 检查语法, 生成编译文件</li><li>汇编: 将汇编文件生成目标文件(二进制文件)</li><li>链接: 将目标文件链接成目标程序</li></ul><p>但如果源文件太多，一个一个编译就会特别麻烦，为什么不批处理编译源文件呢，于是就有了make工具，它是一个自动化编译工具，你可以使用一条命令实现完全编译。还可以指定文件编译的顺序。但是使用make编译源码，需要编写一个规则文件，make依据它来批处理编译，这个文件就是makefile，所以编写makefile文件也是一个程序员所必备的技能。<br> 对于一个大工程，编写makefile实在是件复杂的事，于是人们又想，为什么不设计一个工具，读入所有源文件之后，自动生成makefile呢，于是就出现了<code>cmake</code>工具，它能够输出各种各样的makefile或者project文件,从而帮助程序员减轻负担。但是随之而来也就是编写cmakelist文件，它是cmake所依据的规则。所以在编程的世界里没有捷径可走，还是要脚踏实地的。</p><p> 原文件－－camkelist —cmake —makefile —make —生成可执行文件</p><h1 id="二、CMake基本语法规则"><a href="#二、CMake基本语法规则" class="headerlink" title="二、CMake基本语法规则"></a>二、<code>CMake基本语法规则</code></h1><ol><li><p>变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名</p></li><li><p>指令(参数1  参数2  …)</p><p>参数使用括弧括起，参数之间使用空格或分号分开</p></li><li><p>指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令</p></li><li><p>关于双引号的疑惑</p><pre class="line-numbers language-shell"><code class="language-shell">SET(SRC_LIST main.c)也可以写成 SET(SRC_LIST “main.c”)是没有区别的，但是假设一个源文件的文件名是 fu nc.c(文件名中间包含了空格)。这时候就必须使用双引号，如果写成了 SET(SRC_LIST fu nc.c)，就会出现错误，提示你找不到 fu 文件和 nc.c 文件。这种情况，就必须写成:SET(SRC_LIST “fu nc.c”)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><h1 id="三、内部构建与外部构建"><a href="#三、内部构建与外部构建" class="headerlink" title="三、内部构建与外部构建"></a>三、内部构建与外部构建</h1><p>内部构建就是在项目跟目录直接编译</p><p>引出了我们对外部编译的探讨，外部编译的过程如下：</p><ol><li>首先，请清除 t1 目录中除 main.c CmakeLists.txt 之外的所有中间文件，最关键的是 CMakeCache.txt。</li><li>在 t1 目录中建立 build 目录，当然你也可以在任何地方建立 build 目录，不一定必须在工程目录中。</li><li>进入 build 目录，运行 cmake ..(注意,..代表父目录，因为父目录存在我们需要的CMakeLists.txt，如果你在其他地方建立了 build 目录，需要运行 cmake &lt;工程的全路径&gt;)，查看一下 build 目录，就会发现了生成了编译需要的 Makefile 以及其他的中间文件.</li><li>运行 make 构建工程，就会在当前目录(build 目录)中获得目标文件 hello。</li><li>上述过程就是所谓的 out-of-source 外部编译，一个最大的好处是，对于原有的工程没有任何影响，所有动作全部发生在编译目录。通过这一点，也足以说服我们全部采用外部编译方式构建工程。</li><li>这里需要特别注意的是：<br>通过外部编译进行工程构建，HELLO_SOURCE_DIR 仍然指代工程路径，即/backup/cmake/t1, 而 HELLO_BINARY_DIR 则指代编译路径，即/backup/cmake/t1/build</li></ol><p>#　四、安装库和INSTALL指令</p><p>有两种安装方式，一种是从代码编译后直接 make install 安装，一种是cmake的install 指令安装。</p><h2 id="1、make-install"><a href="#1、make-install" class="headerlink" title="1、make install"></a>1、<code>make install</code></h2><pre class="line-numbers language-shell"><code class="language-shell">DESTDIR=install:    mkdir -p $(DESTDIR)/usr/bin    install -m 755 hello $(DESTDIR)/usr/bin你可以通过:    make install将 hello 直接安装到/usr/bin 目录，也可以通过 make installDESTDIR=/tmp/test 将他安装在/tmp/test/usr/bin 目录，打包时这个方式经常被使用。稍微复杂一点的是还需要定义 PREFIX，一般 autotools 工程，会运行这样的指令:./configure –prefix=/usr 或者./configure --prefix=/usr/local 来指定PREFIX比如上面的 Makefile 就可以改写成:DESTDIR=PREFIX=/usrinstall:    mkdir -p $(DESTDIR)/$(PREFIX)/bin    install -m 755 hello $(DESTDIR)/$(PREFIX)/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2、cmake-INSTALL指令安装"><a href="#2、cmake-INSTALL指令安装" class="headerlink" title="2、cmake INSTALL指令安装"></a>2、<code>cmake INSTALL</code>指令安装</h2><p>这里需要引入一个新的 cmake 指令 INSTALL 和一个非常有用的变量<br>CMAKE_INSTALL_PREFIX。CMAKE_INSTALL_PREFIX 变量类似于 configure 脚本的 –prefix，常见的使用方法看起来是这个样子：<br>    <code>cmake -DCMAKE_INSTALL_PREFIX=/usr ..</code><br>INSTALL 指令用于定义安装规则，安装的内容可以包括目标二进制、动态库、静态库以及文件、目录、脚本等。</p><p>INSTALL 指令包含了各种安装类型，我们需要一个个分开解释：<br>目标文件的安装：</p><pre><code>INSTALL(TARGETS targets...    [[ARCHIVE|LIBRARY|RUNTIME]    [DESTINATION &lt;dir&gt;]    [PERMISSIONS permissions...]    [CONFIGURATIONS [Debug|Release|...]]    [COMPONENT &lt;component&gt;]    [OPTIONAL]] [...])</code></pre><p>参数中的 TARGETS 后面跟的就是我们通过 ADD_EXECUTABLE 或者 ADD_LIBRARY 定义的<br>目标文件，可能是可执行二进制、动态库、静态库。<br>目标类型也就相对应的有三种，ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME<br>特指可执行目标二进制。<br>DESTINATION 定义了安装的路径，如果路径以/开头，那么指的是绝对路径，这时候<br>CMAKE_INSTALL_PREFIX 其实就无效了。如果你希望使用 CMAKE_INSTALL_PREFIX 来<br>定义安装路径，就要写成相对路径，即不要以/开头，那么安装后的路径就是<br>${CMAKE_INSTALL_PREFIX}/&lt;DESTINATION 定义的路径&gt;<br>举个简单的例子：</p><pre class="line-numbers language-shell"><code class="language-shell">INSTALL(TARGETS myrun mylib mystaticlib    RUNTIME DESTINATION bin    LIBRARY DESTINATION lib    ARCHIVE DESTINATION libstatic)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面的例子会将：<br>可执行二进制 myrun 安装到${CMAKE_INSTALL_PREFIX}/bin 目录<br>动态库 libmylib 安装到${CMAKE_INSTALL_PREFIX}/lib 目录<br>静态库 libmystaticlib 安装到${CMAKE_INSTALL_PREFIX}/libstatic 目录<br>特别注意的是你不需要关心 TARGETS 具体生成的路径，只需要写上 TARGETS 名称就可以<br>了。  </p><p>普通文件的安装：</p><pre class="line-numbers language-shell"><code class="language-shell">INSTALL(FILES files... DESTINATION <dir>    [PERMISSIONS permissions...]    [CONFIGURATIONS [Debug|Release|...]]    [COMPONENT <component>]    [RENAME <name>] [OPTIONAL])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可用于安装一般文件，并可以指定访问权限，文件名是此指令所在路径下的相对路径。如果<br>默认不定义权限 PERMISSIONS，安装后的权限为：<br>OWNER_WRITE, OWNER_READ, GROUP_READ,和 WORLD_READ，即 644 权限。<br>非目标文件的可执行程序安装(比如脚本之类)：</p><pre><code>INSTALL(PROGRAMS files... DESTINATION &lt;dir&gt;    [PERMISSIONS permissions...]    [CONFIGURATIONS [Debug|Release|...]]    [COMPONENT &lt;component&gt;]    [RENAME &lt;name&gt;] [OPTIONAL])</code></pre><p>跟上面的 FILES 指令使用方法一样，唯一的不同是安装后权限为:<br>OWNER_EXECUTE, GROUP_EXECUTE, 和 WORLD_EXECUTE，即 755 权限<br>目录的安装：</p><pre class="line-numbers language-shell"><code class="language-shell">INSTALL(DIRECTORY dirs... DESTINATION <dir>    [FILE_PERMISSIONS permissions...]    [DIRECTORY_PERMISSIONS permissions...]    [USE_SOURCE_PERMISSIONS]    [CONFIGURATIONS [Debug|Release|...]]    [COMPONENT <component>]    [[PATTERN <pattern> | REGEX <regex>]    [EXCLUDE] [PERMISSIONS permissions...]] [...])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里主要介绍其中的 DIRECTORY、PATTERN 以及 PERMISSIONS 参数。</p><p>DIRECTORY 后面连接的是所在 Source 目录的相对路径，但务必注意：abc 和 abc/有很大的区别。<br>如果目录名不以/结尾，那么这个目录将被安装为目标路径下的 abc，如果目录名以/结尾，代表将这个目录中的内容安装到目标路径，但不包括这个目录本身。<br>PATTERN 用于使用正则表达式进行过滤，PERMISSIONS 用于指定 PATTERN 过滤后的文件权限。<br>我们来看一个例子:</p><pre class="line-numbers language-shell"><code class="language-shell">INSTALL(DIRECTORY icons scripts/ DESTINATION     share/myprojPATTERN "CVS" EXCLUDEPATTERN "scripts/*"PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READGROUP_EXECUTE GROUP_READ)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这条指令的执行结果是：<br>将 icons 目录安装到 <prefix>/share/myproj，将 scripts/中的内容安装到<prefix>/share/myproj不包含目录名为 CVS 的目录，对于 scripts/*  文件指定权限为 OWNER_EXECUTE   OWNER_WRITE OWNER_READ GROUP_EXECUTE GROUP_READ.</prefix></prefix></p><p>安装时 CMAKE 脚本的执行：</p><pre><code>INSTALL([[SCRIPT &lt;file&gt;] [CODE &lt;code&gt;]] [...])SCRIPT 参数用于在安装时调用 cmake 脚本文件（也就是&lt;abc&gt;.cmake 文件）CODE 参数用于执行 CMAKE 指令，必须以双引号括起来。比如：INSTALL(CODE &quot;MESSAGE(\&quot;Sample install message.\&quot;)&quot;)</code></pre><h1 id="五、静态库和动态库构建"><a href="#五、静态库和动态库构建" class="headerlink" title="五、静态库和动态库构建"></a>五、静态库和动态库构建</h1><h2 id="1、ADD-LIBRARY指令"><a href="#1、ADD-LIBRARY指令" class="headerlink" title="1、ADD_LIBRARY指令"></a>1、ADD_LIBRARY指令</h2><pre class="line-numbers language-shell"><code class="language-shell">ADD_LIBRARY(libname [SHARED|STATIC|MODULE]    [EXCLUDE_FROM_ALL]    source1 source2 ... sourceN)# 不需要写全lib<libname>.so, 只需要填写<libname>,cmake系统会自动为你生成，lib<libname>.X# 类型有三种:    SHARED，动态库    .so    STATIC，静态库    .a    MODULE，在使用 dyld 的系统有效，如果不支持 dyld，则被当作 SHARED 对待。#EXCLUDE_FROM_ALL 参数的意思是这个库不会被默认构建，除非有其他的组件依赖或者手工构建。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2、指定库的生成路径"><a href="#2、指定库的生成路径" class="headerlink" title="2、指定库的生成路径"></a>2、指定库的生成路径</h2><p>​    两种方法</p><ol><li>ADD_SUBDIRECTORY指令来指定一个编译输出位置</li><li>在CMakeLists.txt中添加　SET(LIBRARY_OUTPUT_PATH &lt;路径&gt;)来指定一个新的位置</li></ol><h2 id="3、同时生成动态库和静态库"><a href="#3、同时生成动态库和静态库" class="headerlink" title="3、同时生成动态库和静态库"></a>3、同时生成动态库和静态库</h2><p>因为ADD_SUBDIRECTORY的TARGET(libname)是唯一的，所以生成动态库和静态库不能指定相同的名称，想要有相同的名称需要用到SET_TARGET_PROPERTIES指令。</p><p>SET_TARGET_PROPERTIES，其基本语法是：</p><pre class="line-numbers language-shell"><code class="language-shell">SET_TARGET_PROPERTIES(target1 target2 ...    PROPERTIES prop1 value1    prop2 value2 ...)# 举例ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})　# 动态库ADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC}) # 静态库SET_TARGET_PROPERTIES(hello_static PROPERTIES OUTPUT_NAME "hello")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本。</p><p>与他对应的指令是：<br>    GET_TARGET_PROPERTY(VAR target property)</p><p>举例</p><pre class="line-numbers language-shell"><code class="language-shell">GET_TARGET_PROPERTY(OUTPUT_VALUE hello_static OUTPUT_NAME)MESSAGE(STATUS “This is the hello_staticOUTPUT_NAME:”${OUTPUT_VALUE})# 如果没有这个属性定义，则返回 NOTFOUND.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4、动态库版本号"><a href="#4、动态库版本号" class="headerlink" title="4、动态库版本号"></a>4、动态库版本号</h2><pre class="line-numbers language-shell"><code class="language-shell">SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)# VERSION 指代动态库版本，SOVERSION 指代 API 版本。# 在 build/lib 目录会生成：    libhello.so.1.2    libhello.so.1->libhello.so.1.2    libhello.so -> libhello.so.1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="六、使用共享库和头文件"><a href="#六、使用共享库和头文件" class="headerlink" title="六、使用共享库和头文件"></a>六、使用共享库和头文件</h1><h2 id="1-INCLUDE-DIRECTORIES指令"><a href="#1-INCLUDE-DIRECTORIES指令" class="headerlink" title="1.INCLUDE_DIRECTORIES指令"></a>1.<code>INCLUDE_DIRECTORIES</code>指令</h2><p><code>INCLUDE_DIRECTORIES([AFTER|BEFORE] [SYSTEM] dir1 dir2 ...)</code><br>这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割，如果路径中包含了空格，可以使用双引号将它括起来，默认的行为是追加到当前的头文件搜索路径的<br>后面，你可以通过两种方式来进行控制搜索路径添加的方式：<br>１. CMAKE_INCLUDE_DIRECTORIES_BEFORE，通过 SET 这个 cmake 变量为 on，可以将添加的头文件搜索路径放在已有路径的前面。<br>２. 通过 AFTER 或者 BEFORE 参数，也可以控制是追加还是置前。</p><h2 id="2-LINK-DIRECTORIES和-TARGET-LINK-LIBRARIES"><a href="#2-LINK-DIRECTORIES和-TARGET-LINK-LIBRARIES" class="headerlink" title="2. LINK_DIRECTORIES和 TARGET_LINK_LIBRARIES"></a>2. <code>LINK_DIRECTORIES</code>和 <code>TARGET_LINK_LIBRARIES</code></h2><pre class="line-numbers language-shell"><code class="language-shell">LINK_DIRECTORIES(directory1 directory2 ...)# 这个指令非常简单，添加非标准的共享库搜索路径，比如，在工程内部同时存在共享库和可执行二进制，在编译时就需要指定一下这些共享库的路径。# TARGET_LINK_LIBRARIES 的全部语法是:TARGET_LINK_LIBRARIES(target library1    <debug | optimized> library2...)# 这个指令可以用来为 target 添加需要链接的共享库<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-FIND系列指令"><a href="#3-FIND系列指令" class="headerlink" title="3. FIND系列指令"></a>3. <code>FIND</code>系列指令</h2><ol><li><p>特殊的环境变量<code>CMAKE_INCLUDE_PATH</code> 和<code>CMAKE_LIBRARY_PATH</code></p><p>务必注意，这两个是环境变量而不是 cmake 变量</p></li><li><p><code>CMAKE_INCLUDE_PATH</code>和<code>CMAKE_LIBRARY_PATH</code>是配合<code>FIND_PATH</code>和<code>FIND_LIBRARY</code>指令使用的</p></li><li><p>find_path指令</p><pre class="line-numbers language-shell"><code class="language-shell">find_path (<VAR> NAMES name)# <VAR>查找的库文件路径报存在变量VAR中# 默认搜索路径为`CMAKE_INCLUDE_PATH`find_path (<VAR> NAMES name PATHS paths... [NO_DEFAULT_PATH])#　指定搜索路径# NO_DEFAULT_PATH　不使用默认搜索路径　# 举例为了将程序更智能一点，我们可以使用 CMAKE_INCLUDE_PATH 来进行，使用 bash 的方法如下：export CMAKE_INCLUDE_PATH=/usr/include/hello然后在头文件中将 INCLUDE_DIRECTORIES(/usr/include/hello)替换为：FIND_PATH(myHeader hello.h)IF(myHeader)    INCLUDE_DIRECTORIES(${myHeader})ENDIF(myHeader)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="4-共享库和头文件指令总结"><a href="#4-共享库和头文件指令总结" class="headerlink" title="4. 共享库和头文件指令总结"></a>4. 共享库和头文件指令总结</h2><ol><li><strong>FIND_PATH</strong> 查找头文件所在目录</li><li><strong>INCLUDE_DIRECTORIES</strong>　添加头文件目录</li><li><strong>FIND_LIBRARY</strong> 查找库文件所在目录</li><li><strong>LINK_DIRECTORIES</strong>   添加库文件目录</li><li><strong>LINK_LIBRARIES</strong>　添加需要链接的库文件路径，注意这里是全路径</li><li><em><em>TARGET_LINK_LIBRARIES </em></em>　给TARGET链接库</li></ol><h1 id="七、Find模块"><a href="#七、Find模块" class="headerlink" title="七、Find模块"></a>七、Find模块</h1><h2 id="1-Find模块使用"><a href="#1-Find模块使用" class="headerlink" title="1.Find模块使用"></a>1.Find模块使用</h2><pre class="line-numbers language-shell"><code class="language-shell">FIND_PACKAGE(XXX)IF(XXX_FOUND)    INCLUDE_DIRECTORIES(${XXX_INCLUDE_DIR})    TARGET_LINK_LIBRARIES(xxxtest ${XXX_LIBRARY})ELSE(XXX_FOUND)    MESSAGE(FATAL_ERROR ”XXX library not found”)ENDIF(XXX_FOUND)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于系统预定义的 Find<name>.cmake 模块，使用方法一般如上例所示：<br>每一个模块都会定义以下几个变量<br>    • <name>_FOUND<br>    • <name>_INCLUDE_DIR or <name>_INCLUDES<br>    • <name>_LIBRARY or <name>_LIBRARIES<br>你可以通过<name>_FOUND 来判断模块是否被找到，如果没有找到，按照工程的需要关闭某些特性、给出提醒或者中止编译</name></name></name></name></name></name></name></p><h2 id="2-find-package指令"><a href="#2-find-package指令" class="headerlink" title="2.find_package指令"></a>2.find_package指令</h2><pre class="line-numbers language-shell"><code class="language-shell">find_package(<PackageName> [QUIET] [REQUIRED] [[COMPONENTS] [components...]]             [OPTIONAL_COMPONENTS components...]             [NO_POLICY_SCOPE])# 查找并从外部项目加载设置，# <PackageName>_FOUND 将设置为指示是否找到该软件包, 如果查找到，该变量为true# [QUIET], 设置该变量，不会打印任何消息，且           <PackageName>_FIND_QUIETLY为true# [REQUIRED] 设置该变量，如果找不到软件包，该选项将停止处理并显示一条错误消息，且设置<PackageName>_FIND_REQUIRED为true,不过不指定该参数，即使没有找到，也能编译通过<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>find_package采用两种模式搜索库：</p><ul><li><strong>Module模式</strong>：搜索<strong>CMAKE_MODULE_PATH</strong>指定路径下的<strong>FindXXX.cmake</strong>文件，执行该文件从而找到XXX库。其中，具体查找库并给<strong>XXX_INCLUDE_DIRS</strong>和<strong>XXX_LIBRARIES</strong>两个变量赋值的操作由FindXXX.cmake模块完成。</li><li><strong>Config模式</strong>：搜索<strong>XXX_DIR</strong>指定路径下的<strong>XXXConfig.cmake</strong>文件，执行该文件从而找到XXX库。其中具体查找库并给<strong>XXX_INCLUDE_DIRS</strong>和<strong>XXX_LIBRARIES</strong>两个变量赋值的操作由XXXConfig.cmake模块完成。</li></ul><p>两种模式看起来似乎差不多，不过cmake默认采取<strong>Module</strong>模式，如果Module模式未找到库，才会采取Config模式。如果<strong>XXX_DIR</strong>路径下找不到XXXConfig.cmake或<code>&lt;lower-case-package-name&gt;</code>config.cmake文件，则会找/usr/local/lib/cmake/XXX/中的XXXConfig.cmake文件。总之，Config模式是一个备选策略。通常，库安装时会拷贝一份XXXConfig.cmake到系统目录中，因此在没有显式指定搜索路径时也可以顺利找到。</p><p>总结：CMake搜索的顺序为: 首先在<code>CMAKE_MODULE_PATH</code>中搜索名为<code>Find&lt;PackageName&gt;.cmake</code>的文件，然后在<code>&lt;PackageName&gt;_DIR</code>名为<code>PackageName&gt;Config.cmake</code>或<code>&lt;lower-case-package-name&gt;-config.cmake</code>的文件，如果还是找不到，则会去<code>/usr/local/lib/cmake</code>中查找<code>Find&lt;PackageName&gt;.cmake</code>文件。</p><p>所以我们可以通过<code>CMAKE_MODULE_PATH</code>或<code>&lt;PackageName&gt;_DIR</code>变量指定cmake文件路径。</p><h2 id="3-自定义Find模块"><a href="#3-自定义Find模块" class="headerlink" title="3.自定义Find模块"></a>3.自定义Find模块</h2><pre class="line-numbers language-shell"><code class="language-shell"># 查找HELLO的头文件目录FIND_PATH(HELLO_INCLUDE_DIR hello.h /usr/include/hello/usr/local/include/hello)# 查找HELLO的动态库FIND_LIBRARY(HELLO_LIBRARY NAMES hello PATH /usr/lib/usr/local/lib)IF (HELLO_INCLUDE_DIR AND HELLO_LIBRARY)    SET(HELLO_FOUND TRUE)ENDIF (HELLO_INCLUDE_DIR AND HELLO_LIBRARY)IF (HELLO_FOUND)    # 如果不指定QUIET参数，就打印信息    IF (NOT HELLO_FIND_QUIETLY)        MESSAGE(STATUS "Found Hello: ${HELLO_LIBRARY}")    ENDIF (NOT HELLO_FIND_QUIETLY)ELSE (HELLO_FOUND)    # 如果设置了REQUIRED参数就报错    IF (HELLO_FIND_REQUIRED)        MESSAGE(FATAL_ERROR "Could not find hello library")    ENDIF (HELLO_FIND_REQUIRED)ENDIF (HELLO_FOUND)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="八、CMake常用变量"><a href="#八、CMake常用变量" class="headerlink" title="八、CMake常用变量"></a>八、<code>CMake</code>常用变量</h1><h2 id="1-cmake-变量引用的方式："><a href="#1-cmake-变量引用的方式：" class="headerlink" title="1.cmake 变量引用的方式："></a>1.<code>cmake</code> 变量引用的方式：</h2><p>使用${}进行变量的引用。在 IF 等语句中，是直接使用变量名而不通过${}取值</p><h2 id="2-cmake-自定义变量的方式："><a href="#2-cmake-自定义变量的方式：" class="headerlink" title="2.cmake 自定义变量的方式："></a>2.<code>cmake</code> 自定义变量的方式：</h2><p>主要有隐式定义和显式定义两种，前面举了一个隐式定义的例子，就是 PROJECT 指令，他会隐式的定义<projectname>_BINARY_DIR 和<projectname>_SOURCE_DIR 两个变量。<br>显式定义的例子我们前面也提到了，使用 SET 指令，就可以构建一个自定义变量了。比如:</projectname></projectname></p><p>SET(HELLO_SRC main.SOURCE_PATHc)，就PROJECT_BINARY_DIR 可以通过${HELLO_SRC}来引用这个自定义变量了.</p><h2 id="3-cmake-常用变量"><a href="#3-cmake-常用变量" class="headerlink" title="3.cmake 常用变量"></a>3.<code>cmake</code> 常用变量</h2><h3 id="1-CMAKE-BINARY-DIR-PROJECT-BINARY-DIR-BINARY-DIR"><a href="#1-CMAKE-BINARY-DIR-PROJECT-BINARY-DIR-BINARY-DIR" class="headerlink" title="1. CMAKE_BINARY_DIR/PROJECT_BINARY_DIR/_BINARY_DIR_"></a>1. CMAKE_BINARY_DIR/PROJECT_BINARY_DIR/<projectname>_BINARY_DIR_</projectname></h3><p>这三个变量指代的内容是一致的，如果是 in source 编译，指得就是工程顶层目录，如果是 out-of-source 编译，指的是工程编译发生的目录。PROJECT_BINARY_DIR 跟其他指令稍有区别，现在，你可以理解为他们是一致的。</p><h3 id="2-CMAKE-SOURCE-DIR-PROJECT-SOURCE-DIR-SOURCE-DIR"><a href="#2-CMAKE-SOURCE-DIR-PROJECT-SOURCE-DIR-SOURCE-DIR" class="headerlink" title="2. CMAKE_SOURCE_DIR/PROJECT_SOURCE_DIR/_SOURCE_DIR"></a>2. CMAKE_SOURCE_DIR/PROJECT_SOURCE_DIR/<projectname>_SOURCE_DIR</projectname></h3><p>这三个变量指代的内容是一致的，不论采用何种编译方式，都是工程顶层目录。</p><h3 id="3-CMAKE-CURRENT-SOURCE-DIR"><a href="#3-CMAKE-CURRENT-SOURCE-DIR" class="headerlink" title="3. CMAKE_CURRENT_SOURCE_DIR"></a>3. CMAKE_CURRENT_SOURCE_DIR</h3><p>指的是<strong>当前处理的</strong> CMakeLists.txt 所在的路径</p><h3 id="4-CMAKE-CURRRENT-BINARY-DIR"><a href="#4-CMAKE-CURRRENT-BINARY-DIR" class="headerlink" title="4. CMAKE_CURRRENT_BINARY_DIR"></a>4. CMAKE_CURRRENT_BINARY_DIR</h3><p>如果是 in-source 编译，它跟 CMAKE_CURRENT_SOURCE_DIR 一致，如果是 out-ofsource 编译，他指的是 target 编译目录。<br>使用我们上面提到的 ADD_SUBDIRECTORY(src bin)可以更改这个变量的值。<br>使用 SET(EXECUTABLE_OUTPUT_PATH &lt;新路径&gt;)并不会对这个变量造成影响，它仅仅修改了最终目标文件存放的路径。</p><h3 id="５-CMAKE-CURRENT-LIST-FILE"><a href="#５-CMAKE-CURRENT-LIST-FILE" class="headerlink" title="５. CMAKE_CURRENT_LIST_FILE"></a>５. CMAKE_CURRENT_LIST_FILE</h3><p>​    输出调用这个变量的 CMakeLists.txt 的完整路径</p><h3 id="6-CMAKE-CURRENT-LIST-LINE"><a href="#6-CMAKE-CURRENT-LIST-LINE" class="headerlink" title="6. CMAKE_CURRENT_LIST_LINE"></a>6. CMAKE_CURRENT_LIST_LINE</h3><p>​    输出这个变量所在的行</p><h3 id="7-CMAKE-MODULE-PATH"><a href="#7-CMAKE-MODULE-PATH" class="headerlink" title="7. CMAKE_MODULE_PATH"></a>7. CMAKE_MODULE_PATH</h3><p>这个变量用来定义自己的 cmake 模块所在的路径。如果你的工程比较复杂，有可能会自己编写一些 cmake 模块，这些 cmake 模块是随你的工程发布的，为了让 cmake 在处理CMakeLists.txt 时找到这些模块，你需要通过 SET 指令，将自己的 cmake 模块路径设<br>置一下。比如<br>SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)<br>这时候你就可以通过 INCLUDE 指令来调用自己的模块了。</p><h3 id="8-EXECUTABLE-OUTPUT-PATH-和-LIBRARY-OUTPUT-PATH"><a href="#8-EXECUTABLE-OUTPUT-PATH-和-LIBRARY-OUTPUT-PATH" class="headerlink" title="8. EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH"></a>8. EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH</h3><p>分别用来重新定义最终结果的存放目录，前面我们已经提到了这两个变量。</p><h3 id="9-PROJECT-NAME"><a href="#9-PROJECT-NAME" class="headerlink" title="9. PROJECT_NAME"></a>9. PROJECT_NAME</h3><p>返回通过 PROJECT 指令定义的项目名称。</p><h2 id="4-cmake-调用环境变量的方式"><a href="#4-cmake-调用环境变量的方式" class="headerlink" title="4. cmake 调用环境变量的方式"></a>4. cmake 调用环境变量的方式</h2><p>使用$ENV{NAME}指令就可以调用系统的环境变量了。<br>比如MESSAGE(STATUS “HOME dir: $ENV{HOME}”)<br>设置环境变量的方式是：SET(ENV{变量名} 值)</p><h3 id="1-CMAKE-INCLUDE-CURRENT-DIR"><a href="#1-CMAKE-INCLUDE-CURRENT-DIR" class="headerlink" title="1. CMAKE_INCLUDE_CURRENT_DIR"></a>1. CMAKE_INCLUDE_CURRENT_DIR</h3><p>自动添加 CMAKE_CURRENT_BINARY_DIR 和 CMAKE_CURRENT_SOURCE_DIR 到当前处理<br>的 CMakeLists.txt。相当于在每个 CMakeLists.txt 加入：<br>INCLUDE_DIRECTORIES(${CMAKE_CURRENT_BINARY_DIR}<br>${CMAKE_CURRENT_SOURCE_DIR})</p><h3 id="2-CMAKE-INCLUDE-DIRECTORIES-PROJECT-BEFORE"><a href="#2-CMAKE-INCLUDE-DIRECTORIES-PROJECT-BEFORE" class="headerlink" title="2. CMAKE_INCLUDE_DIRECTORIES_PROJECT_BEFORE"></a>2. CMAKE_INCLUDE_DIRECTORIES_PROJECT_BEFORE</h3><p>将工程提供的头文件目录始终至于系统头文件目录的前面，当你定义的头文件确实跟系统发生冲突时可以提供一些帮助。</p><h3 id="3-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH-我们在上一节已经提及。"><a href="#3-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH-我们在上一节已经提及。" class="headerlink" title="3. CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH 我们在上一节已经提及。"></a>3. CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH 我们在上一节已经提及。</h3><h2 id="5-系统信息"><a href="#5-系统信息" class="headerlink" title="5. 系统信息"></a>5. 系统信息</h2><ol><li><p>CMAKE_MAJOR_VERSION，CMAKE 主版本号，比如 2.4.6 中的 2</p></li><li><p>CMAKE_MINOR_VERSION，CMAKE 次版本号，比如 2.4.6 中的 4</p></li><li><p>CMAKE_PATCH_VERSION，CMAKE 补丁等级，比如 2.4.6 中的 6</p></li><li><p>CMAKE_SYSTEM，系统名称，比如 Linux-2.6.22</p></li><li><p>CMAKE_SYSTEM_NAME，不包含版本的系统名，比如 Linux</p></li><li><p>CMAKE_SYSTEM_VERSION，系统版本，比如 2.6.22</p></li><li><p>CMAKE_SYSTEM_PROCESSOR，处理器名称，比如 i686.</p></li><li><p>UNIX，在所有的类 UNIX 平台为 TRUE，包括 OS X 和 cygwin</p></li><li><p>WIN32，在所有的 win32 平台为 TRUE，包括 cygwin</p></li></ol><h2 id="6-主要的开关选项："><a href="#6-主要的开关选项：" class="headerlink" title="6.主要的开关选项："></a>6.主要的开关选项：</h2><ol><li><p>CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS，用来控制 IF ELSE 语句的书写方式，在<br>下一节语法部分会讲到。</p></li><li><p>BUILD_SHARED_LIBS<br>这个开关用来控制默认的库编译方式，如果不进行设置，使用 ADD_LIBRARY 并没有指定库类型的情况下，默认编译生成的库都是静态库。<br>如果 SET(BUILD_SHARED_LIBS ON)后，默认生成的为动态</p></li><li><p>CMAKE_C_FLAGS<br>设置 C 编译选项，也可以通过指令 ADD_DEFINITIONS()添加。</p></li><li><p>CMAKE_CXX_FLAGS<br>设置 C++编译选项，也可以通过指令 ADD_DEFINITIONS()添加。</p></li></ol><h1 id="九、CMake常用指令"><a href="#九、CMake常用指令" class="headerlink" title="九、CMake常用指令"></a>九、<code>CMake</code>常用指令</h1><h2 id="1-基本指令"><a href="#1-基本指令" class="headerlink" title="1. 基本指令"></a>1. 基本指令</h2><h3 id="MESSAGE"><a href="#MESSAGE" class="headerlink" title="MESSAGE"></a>MESSAGE</h3><pre class="line-numbers language-shell"><code class="language-shell">message([<mode>] "message to display" ...)可选<mode>关键字确定消息的类型:FATAL_ERROR    立即终止所有 cmake 过程SEND_ERROR 产生错误，生成过程被跳过WARNINGAUTHOR_WARNINGNOTICESTATUS    输出前缀为—的信息VERBOSEDEBUGTRACE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="PROJECT"><a href="#PROJECT" class="headerlink" title="PROJECT"></a>PROJECT</h3><pre class="line-numbers language-shell"><code class="language-shell">project(<PROJECT-NAME> [<language-name>...])project(<PROJECT-NAME>        [VERSION <major>[.<minor>[.<patch>[.<tweak>]]]]        [LANGUAGES <language-name>...])设置项目的名称，并将其存储在变量中 PROJECT_NAME。从顶层调用时， CMakeLists.txt还将项目名称存储在变量CMAKE_PROJECT_NAME中。同时设置变量PROJECT_SOURCE_DIR， <PROJECT-NAME>_SOURCE_DIRPROJECT_BINARY_DIR， <PROJECT-NAME>_BINARY_DIRhttps://cmake.org/cmake/help/v3.15/command/project.html<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h3><pre class="line-numbers language-shell"><code class="language-shell">将普通变量，缓存变量或环境变量设置为给定值。指定<value>...占位符的此命令的签名期望零个或多个参数。多个参数将以分号分隔的列表形式加入，以形成要设置的实际变量值。零参数将导致未设置普通变量。unset() 命令显式取消设置变量。1、设置正常变量set(<variable> <value>... [PARENT_SCOPE])<variable>在当前函数或目录范围内设置给定值。如果PARENT_SCOPE给出了该选项，则将在当前作用域上方的作用域中设置变量。2、设置缓存变量set(<variable> <value>... CACHE <type> <docstring> [FORCE])3、设置环境变量set(ENV{<variable>} [<value>])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="add-executable"><a href="#add-executable" class="headerlink" title="add_executable"></a>add_executable</h3><pre class="line-numbers language-shell"><code class="language-shell">使用指定的源文件生成可执行文件add_executable(<name> [WIN32] [MACOSX_BUNDLE]               [EXCLUDE_FROM_ALL]               [source1] [source2 ...])<name>可执行文件名, <name>与逻辑目标名称相对应，并且在项目中必须是全局唯一的。构建的可执行文件的实际文件名是基于本机平台（例如<name>.exe或<name>）的约定构造的 。默认情况下，将在与调用命令的源树目录相对应的构建树目录中创建可执行文件。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="add-subdirectory"><a href="#add-subdirectory" class="headerlink" title="add_subdirectory"></a>add_subdirectory</h3><pre class="line-numbers language-shell"><code class="language-shell">在构建中添加一个子目录。add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL])将一个子目录添加到构建中。source_dir指定源CMakeLists.txt和代码文件所在的目录。binary_dir指定了输出文件放置的目录以及编译输出的路径。EXCLUDE_FROM_ALL 参数的含义是将这个目录从编译过程中排除，比如，工程的 example，可能就需要工程构建完成后，再进入 example 目录单独进行构建(当然，你也可以通过定义依赖来解决此类问题)。如果没有指定binary_dir,那么编译结果(包括中间结果)都将存放在build/source_dir 目录(这个目录跟原有的 source_dir 目录对应)，指定binary_dir 目录后，相当于在编译时将 source_dir 重命名为binary_dir，所有的中间结果和目标二进制都将存放在binary_dir 目录。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="subdirs"><a href="#subdirs" class="headerlink" title="subdirs"></a>subdirs</h3><pre class="line-numbers language-shell"><code class="language-shell">构建多个子目录subdirs(dir1 dir2 ...[EXCLUDE_FROM_ALL exclude_dir1 exclude_dir2 ...]        [PREORDER] )不论是 SUBDIRS 还是 ADD_SUBDIRECTORY 指令(不论是否指定编译输出目录)，我们都可以通过 SET 指令重新定义EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量来指定最终的目标二进制的位置(指最终生成的 hello 或者最终的共享库，不包含编译生成的中间文件)SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)在第一节我们提到了<projectname>_BINARY_DIR 和 PROJECT_BINARY_DIR 变量，他们指的编译发生的当前目录，如果是内部编译，就相当于 PROJECT_SOURCE_DIR 也就是工程代码所在目录，如果是外部编译，指的是外部编译所在目录，也就是本例中的两个指令分别定义了：可执行二进制的输出路径为 build/bin 和库的输出路径为 build/lib.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="add-library"><a href="#add-library" class="headerlink" title="add_library"></a>add_library</h3><pre class="line-numbers language-shell"><code class="language-shell">ADD_LIBRARY(libname [SHARED|STATIC|MODULE][EXCLUDE_FROM_ALL]source1 source2 ... sourceN)你不需要写全 libhello.so，只需要填写 hello 即可，cmake 系统会自动为你生成libhello.X类型有三种:SHARED，动态库STATIC，静态库MODULE，在使用 dyld 的系统有效，如果不支持 dyld，则被当作 SHARED 对待。EXCLUDE_FROM_ALL 参数的意思是这个库不会被默认构建，除非有其他的组件依赖或者手工构建。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="include-directories"><a href="#include-directories" class="headerlink" title="include_directories"></a>include_directories</h3><pre class="line-numbers language-shell"><code class="language-shell">将include目录添加到构建中include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])将给定目录添加到编译器用于搜索头文件的路径中。这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割，如果路径中包含了空格，可以使用双引号将它括起来，默认的行为是追加到当前的头文件搜索路径的后面，你可以通过两种方式来进行控制搜索路径添加的方式：１，CMAKE_INCLUDE_DIRECTORIES_BEFORE，通过 SET 这个 cmake 变量为 on，可以将添加的头文件搜索路径放在已有路径的前面。２，通过 AFTER 或者 BEFORE 参数，也可以控制是追加还是置前。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="target-link-libraries-amp-link-directories"><a href="#target-link-libraries-amp-link-directories" class="headerlink" title="target_link_libraries &amp; link_directories"></a>target_link_libraries &amp; link_directories</h3><pre class="line-numbers language-shell"><code class="language-shell">TARGET_LINK_LIBRARIES(target library1<debug | optimized> library2...)这个指令可以用来为 target 添加需要链接的共享库，本例中是一个可执行文件，但是同样可以用于为自己编写的共享库添加共享库链接。为了解决我们前面遇到的 HelloFunc 未定义错误，我们需要作的是向src/CMakeLists.txt 中添加如下指令：TARGET_LINK_LIBRARIES(main hello)也可以写成TARGET_LINK_LIBRARIES(main libhello.so)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ADD-DEFINITIONS"><a href="#ADD-DEFINITIONS" class="headerlink" title="ADD_DEFINITIONS"></a>ADD_DEFINITIONS</h3><pre class="line-numbers language-shell"><code class="language-shell">向 C/C++编译器添加-D 定义，比如:ADD_DEFINITIONS(-DENABLE_DEBUG -DABC)，参数之间用空格分割。如果你的代码中定义了#ifdef ENABLE_DEBUG #endif，这个代码块就会生效。如果要添加其他的编译器开关，可以通过 CMAKE_C_FLAGS 变量和 CMAKE_CXX_FLAGS 变量设置。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="ADD-DEPENDENCIES"><a href="#ADD-DEPENDENCIES" class="headerlink" title="ADD_DEPENDENCIES"></a>ADD_DEPENDENCIES</h3><pre class="line-numbers language-shell"><code class="language-shell">定义 target 依赖的其他 target，确保在编译本 target 之前，其他的 target 已经被构建。ADD_DEPENDENCIES(target-name depend-target1depend-target2 ...)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="ADD-TEST-与-ENABLE-TESTING-指令。"><a href="#ADD-TEST-与-ENABLE-TESTING-指令。" class="headerlink" title="ADD_TEST 与 ENABLE_TESTING 指令。"></a>ADD_TEST 与 ENABLE_TESTING 指令。</h3><pre class="line-numbers language-shell"><code class="language-shell">ENABLE_TESTING 指令用来控制 Makefile 是否构建 test 目标，涉及工程所有目录。语法很简单，没有任何参数，ENABLE_TESTING()，一般情况这个指令放在工程的主CMakeLists.txt 中.ADD_TEST 指令的语法是:    `ADD_TEST(testname Exename arg1 arg2 ...)`testname 是自定义的 test 名称，Exename 可以是构建的目标文件也可以是外部脚本等等。后面连接传递给可执行文件的参数。如果没有在同一个 CMakeLists.txt 中打开    ENABLE_TESTING()指令，任何 ADD_TEST 都是无效的。比如我们前面的 Helloworld 例子，可以在工程主 CMakeLists.txt 中添加ADD_TEST(mytest ${PROJECT_BINARY_DIR}/bin/main)ENABLE_TESTING()生成 Makefile 后，就可以运行 make test 来执行测试了。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="AUX-SOURCE-DIRECTORY"><a href="#AUX-SOURCE-DIRECTORY" class="headerlink" title="AUX_SOURCE_DIRECTORY"></a>AUX_SOURCE_DIRECTORY</h3><pre class="line-numbers language-shell"><code class="language-shell">基本语法是：AUX_SOURCE_DIRECTORY(dir VARIABLE)作用是发现一个目录下所有的源代码文件并将列表存储在一个变量中，这个指令临时被用来自动构建源文件列表。因为目前 cmake 还不能自动发现新添加的源文件。比如AUX_SOURCE_DIRECTORY(. SRC_LIST)ADD_EXECUTABLE(main ${SRC_LIST})你也可以通过后面提到的 FOREACH 指令来处理这个 LIST<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>###　CMAKE_MINIMUM_REQUIRED</p><pre class="line-numbers language-sehll"><code class="language-sehll">其语法为 CMAKE_MINIMUM_REQUIRED(VERSION versionNumber [FATAL_ERROR])比如 CMAKE_MINIMUM_REQUIRED(VERSION 2.5 FATAL_ERROR)如果 cmake 版本小与 2.5，则出现严重错误，整个过程中止。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="EXEC-PROGRAM"><a href="#EXEC-PROGRAM" class="headerlink" title="EXEC_PROGRAM"></a>EXEC_PROGRAM</h3><p>在 CMakeLists.txt 处理过程中执行命令，并不会在生成的 Makefile 中执行。具体语法为：</p><pre class="line-numbers language-shell"><code class="language-shell">EXEC_PROGRAM(Executable [directory in which to run][ARGS <arguments to executable>][OUTPUT_VARIABLE <var>][RETURN_VALUE <var>])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>用于在指定的目录运行某个程序，通过 ARGS 添加参数，如果要获取输出和返回值，可通过OUTPUT_VARIABLE 和 RETURN_VALUE 分别定义两个变量.<br>这个指令可以帮助你在 CMakeLists.txt 处理过程中支持任何命令，比如根据系统情况去修改代码文件等等。<br>举个简单的例子，我们要在 src 目录执行 ls 命令，并把结果和返回值存下来。<br>可以直接在 src/CMakeLists.txt 中添加：<br>EXEC_PROGRAM(ls ARGS “<em>.c” OUTPUT_VARIABLE LS_OUTPUT RETURN_VALUE LS_RVALUE)<br>IF(not LS_RVALUE)<br>    MESSAGE(STATUS “ls result: “ ${LS_OUTPUT})<br>ENDIF(not LS_RVALUE)<br>在 cmake 生成 Makefile 的过程中，就会执行 ls 命令，如果返回 0，则说明成功执行，<br>那么就输出 ls </em>.c 的结果。关于 IF 语句，后面的控制指令会提到。</p><h3 id="FILE-指令"><a href="#FILE-指令" class="headerlink" title="FILE 指令"></a>FILE 指令</h3><p>文件操作指令，基本语法为:</p><pre class="line-numbers language-shell"><code class="language-shell">FILE(WRITE filename "message to write"... )FILE(APPEND filename "message to write"... )FILE(READ filename variable)FILE(GLOB variable [RELATIVE path] [globbingexpressions]...)FILE(GLOB_RECURSE variable [RELATIVE path][globbing expressions]...)FILE(REMOVE [directory]...)FILE(REMOVE_RECURSE [directory]...)FILE(MAKE_DIRECTORY [directory]...)FILE(RELATIVE_PATH variable directory file)FILE(TO_CMAKE_PATH path result)FILE(TO_NATIVE_PATH path result)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里的语法都比较简单，不在展开介绍了。</p><h3 id="INCLUDE-指令"><a href="#INCLUDE-指令" class="headerlink" title="INCLUDE 指令"></a>INCLUDE 指令</h3><pre class="line-numbers language-shell"><code class="language-shell">用来载入 CMakeLists.txt 文件，也用于载入预定义的 cmake 模块.    INCLUDE(file1 [OPTIONAL])    INCLUDE(module [OPTIONAL])OPTIONAL 参数的作用是文件不存在也不会产生错误。你可以指定载入一个文件，如果定义的是一个模块，那么将在 CMAKE_MODULE_PATH 中搜索这个模块并载入。载入的内容将在处理到 INCLUDE 语句是直接执行。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-控制指令："><a href="#2-控制指令：" class="headerlink" title="2. 控制指令："></a>2. 控制指令：</h2><h3 id="1-IF-指令"><a href="#1-IF-指令" class="headerlink" title="1. IF 指令"></a>1. IF 指令</h3><p>基本语法为：</p><pre class="line-numbers language-shell"><code class="language-shell">IF(expression)# THEN section.COMMAND1(ARGS ...)COMMAND2(ARGS ...)...ELSE(expression)# ELSE section.COMMAND1(ARGS ...)COMMAND2(ARGS ...)...ENDIF(expression)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外一个指令是 ELSEIF，总体把握一个原则，凡是出现 IF 的地方一定要有对应的<br>ENDIF.出现 ELSEIF 的地方，ENDIF 是可选的。<br>表达式的使用方法如下:<br>IF(var)，如果变量不是：空，0，N, NO, OFF, FALSE, NOTFOUND 或<br><var>_NOTFOUND 时，表达式为真。<br>IF(NOT var )，与上述条件相反。<br>IF(var1 AND var2)，当两个变量都为真是为真。<br>IF(var1 OR var2)，当两个变量其中一个为真时为真。<br>IF(COMMAND cmd)，当给定的 cmd 确实是命令并可以调用是为真。<br>IF(EXISTS dir)或者 IF(EXISTS file)，当目录名或者文件名存在时为真。<br>IF(file1 IS_NEWER_THAN file2)，当 file1 比 file2 新，或者 file1/file2 其中有一个不存在时为真，文件名请使用完整路径。<br>IF(IS_DIRECTORY dirname)，当 dirname 是目录时，为真。<br>IF(variable MATCHES regex)<br>IF(string MATCHES regex)<br>当给定的变量或者字符串能够匹配正则表达式 regex 时为真。比如：<br>IF(“hello” MATCHES “ell”)<br>MESSAGE(“true”)<br>ENDIF(“hello” MATCHES “ell”)<br>IF(variable LESS number)<br>IF(string LESS number)<br>IF(variable GREATER number)<br>IF(string GREATER number)<br>IF(variable EQUAL number)<br>IF(string EQUAL number)<br>数字比较表达式<br>IF(variable STRLESS string)<br>IF(string STRLESS string)<br>IF(variable STRGREATER string)<br>IF(string STRGREATER string)<br>IF(variable STREQUAL string)<br>IF(string STREQUAL string)<br>按照字母序的排列进行比较.<br>IF(DEFINED variable)，如果变量被定义，为真。<br>一个小例子，用来判断平台差异：<br>IF(WIN32)<br>MESSAGE(STATUS “This is windows.”)</var></p><p>#作一些 Windows 相关的操作<br>ELSE(WIN32)<br>MESSAGE(STATUS “This is not windows”)</p><p>#作一些非 Windows 相关的操作<br>ENDIF(WIN32)<br>上述代码用来控制在不同的平台进行不同的控制，但是，阅读起来却并不是那么舒服，<br>ELSE(WIN32)之类的语句很容易引起歧义。<br>这就用到了我们在“常用变量”一节提到的 CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS 开<br>关。<br>可以 SET(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS ON)<br>这时候就可以写成:<br>IF(WIN32)<br>ELSE()<br>ENDIF()<br>如果配合 ELSEIF 使用，可能的写法是这样:<br>IF(WIN32)</p><p>#do something related to WIN32<br>ELSEIF(UNIX)</p><p>#do something related to UNIX<br>ELSEIF(APPLE)</p><p>#do something related to APPLE<br>ENDIF(WIN32)</p><h3 id="2-WHILE"><a href="#2-WHILE" class="headerlink" title="2. WHILE"></a>2. WHILE</h3><p>WHILE 指令的语法是：</p><pre class="line-numbers language-shell"><code class="language-shell">WHILE(condition)COMMAND1(ARGS ...)COMMAND2(ARGS ...)...ENDWHILE(condition)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其真假判断条件可以参考 IF 指令。</p><h3 id="3-FOREACH"><a href="#3-FOREACH" class="headerlink" title="3. FOREACH"></a>3. FOREACH</h3><p>FOREACH 指令的使用方法有三种形式：</p><pre class="line-numbers language-shell"><code class="language-shell">1，列表FOREACH(loop_var arg1 arg2 ...)COMMAND1(ARGS ...)COMMAND2(ARGS ...)...ENDFOREACH(loop_var)像我们前面使用的 AUX_SOURCE_DIRECTORY 的例子AUX_SOURCE_DIRECTORY(. SRC_LIST)FOREACH(F ${SRC_LIST})MESSAGE(${F})ENDFOREACH(F)2，范围FOREACH(loop_var RANGE total)ENDFOREACH(loop_var)从 0 到 total 以１为步进举例如下：FOREACH(VAR RANGE 10)MESSAGE(${VAR})ENDFOREACH(VAR)最终得到的输出是：0 1 2 3 4 5 6 7 8 910３，范围和步进FOREACH(loop_var RANGE start stop [step])ENDFOREACH(loop_var)从 start 开始到 stop 结束，以 step 为步进，举例如下FOREACH(A RANGE 5 15 3)MESSAGE(${A})ENDFOREACH(A)最终得到的结果是：5 81114这个指令需要注意的是，知道遇到 ENDFOREACH 指令，整个语句块才会得到真正的执行。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="十、CMakeLists配置模板"><a href="#十、CMakeLists配置模板" class="headerlink" title="十、CMakeLists配置模板"></a>十、<code>CMakeLists</code>配置模板</h1><h2 id="１-基本配置"><a href="#１-基本配置" class="headerlink" title="１.基本配置"></a>１.基本配置</h2><pre class="line-numbers language-shell"><code class="language-shell">cmake_minimum_required(VERSION 3.14)project(XXX_Project)# 设置CMAKE版本set(CMAKE_CXX_STANDARD 14)# 设置输出目录为 build/Debug/bin build/Debug/lib# 并缓存路径set(OUTPUT_DIRECTORY_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/build/${CMAKE_BUILD_TYPE})set(CMAKE_RUNTIME_OUTPUT_DIRECTORY "${OUTPUT_DIRECTORY_ROOT}/bin" CACHE PATH "Runtime directory" FORCE)set(CMAKE_LIBRARY_OUTPUT_DIRECTORY "${OUTPUT_DIRECTORY_ROOT}/lib" CACHE PATH "Library directory" FORCE)set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY "${OUTPUT_DIRECTORY_ROOT}/lib" CACHE PATH "Archive directory" FORCE)# 添加src子目录add_subdirectory(src)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="２-依赖库相关配置"><a href="#２-依赖库相关配置" class="headerlink" title="２.依赖库相关配置"></a>２.依赖库相关配置</h2><p><strong><code>OPenCV</code>依赖库</strong></p><p>将<code>OpenCV</code>依赖库下的<code>share/OpenCV</code>中，<code>OpenCVConfig.cmake</code>复制一份叫<code>FindOpenCV.cmake</code>，然后在根目录的CMakeLists.txt添加如下配置</p><pre class="line-numbers language-shell"><code class="language-shell">#　添加make文件搜索路径set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ~/3rdparty/OpenCV-3.4.7/share/OpenCV)# 查找cmake文件，并初始化变量find_package(OpenCV REQUIRED)# 添加头文件搜索路径include_directories(${OpenCV_INCLUDE_DIRS})# 给执行程序添加链接库add_executable(XXXXMain main.cpp)target_link_libraries(XXXXMain ${OpenCV_LIBS})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="十一、参考"><a href="#十一、参考" class="headerlink" title="十一、参考"></a>十一、参考</h1><ol><li>[<a href="http://file.ncnynl.com/ros/CMake%20Practice.pdf]" target="_blank" rel="noopener">http://file.ncnynl.com/ros/CMake%20Practice.pdf]</a>(<a href="http://file.ncnynl.com/ros/CMake" target="_blank" rel="noopener">http://file.ncnynl.com/ros/CMake</a> Practice.pdf)</li><li><a href="https://cmake.org/cmake/help/latest/guide/tutorial/index.html" target="_blank" rel="noopener">https://cmake.org/cmake/help/latest/guide/tutorial/index.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CMake </tag>
            
            <tag> Make </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+Github博客搭建</title>
      <link href="/2019/11/15/hexo-github-bo-ke-da-jian/"/>
      <url>/2019/11/15/hexo-github-bo-ke-da-jian/</url>
      
        <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=4913023&auto=1&height=66"></iframe><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>​    <strong>准备工作</strong></p><ul><li>Github账号</li><li>node.js、hexo、npm安装</li></ul><h1 id="一、安装node-js"><a href="#一、安装node-js" class="headerlink" title="一、安装node.js"></a>一、安装node.js</h1><ol><li><p>下载windows版node.js</p><p>下载地址: <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a></p><p>选择Windows Installer(.msi) 64-bit</p></li><li><p>双击node-v12.13.0-x64.msi, 一直next安装完成</p></li><li><p>测试是否安装成功</p><p>win+R键，输入cmd,然后回车，打开cmd窗口</p><p>输入node -v     显示node.js版本</p><p>输入npm -v     显示npm版本</p><p>安装完成</p></li></ol><h1 id="二、安装hexo"><a href="#二、安装hexo" class="headerlink" title="二、安装hexo"></a>二、安装hexo</h1><ol><li><p>先创建hexo的安装目录, 例如:  F:\LearnSpace\Blog</p></li><li><p>cd Blob  进入Blob目录</p></li><li><p>npm install hexo-cli -g    安装hexo</p></li><li><p>hexo -v  验证是否安装成功</p></li><li><p>npm init blog    初始化blog文件夹，存放博客</p></li><li><p>npm install 安装必备组件</p></li><li><p>cd blog</p></li><li><p>hexo g    生成静态网页</p></li><li><p>hexo s     打开本地服务器</p></li><li><p><a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a>    打开网页</p></li><li><p>ctrl + c   关闭本地服务器</p></li></ol><h1 id="三、连接Github与本地"><a href="#三、连接Github与本地" class="headerlink" title="三、连接Github与本地"></a>三、连接Github与本地</h1><ol><li><p>新建一个名为<code>你的github用户名.github.io</code>的仓库，比如说，如果你的<code>Github</code>用户名是test，那么你就新建<code>test.github.io</code>的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是<code>http://test.github.io</code> 了。</p><p>点击<code>Settings</code>，向下拉到最后有个<code>GitHub Pages</code>，点击<code>Choose a theme</code>选择一个主题。然后等一会儿，再回到<code>GitHub Pages</code>, 就会像下面一样</p><p><img src="2.png" alt></p></li><li><p>修改配置文件</p><p>编辑blog根目录下的<code>_config.yml</code>, 修改最后一行的配置</p></li></ol><pre><code>deploy:  type: git  repository: https://github.com/981935539/981935539.github.io.git  branch: master</code></pre><ol start="3"><li>安装Git部署插件: <code>npm install hexo-deployer-git --save</code></li></ol><h1 id="四、编辑第一篇博客"><a href="#四、编辑第一篇博客" class="headerlink" title="四、编辑第一篇博客"></a>四、编辑第一篇博客</h1><pre><code>hexo new post &quot;first-article&quot;  # 创建第一篇博客hexo g  # 生成静态网页hexo s  # 本地预览效果hexo d  # 上传github</code></pre><p>此时可以在github.io主页就能看到发布的文章啦。</p><h1 id="五、绑定域名"><a href="#五、绑定域名" class="headerlink" title="五、绑定域名"></a>五、绑定域名</h1><ol><li>以阿里云为例，如下图所示，添加两条解析记录:</li></ol><p>​    <img src="1.png" alt></p><ol start="2"><li><p>然后打开你的Github博客项目，点击<code>settings</code>，拉到下面<code>Custom domain</code>处，填上你自己的域名，保存</p></li><li><p>这时候你的<code>F:\LearnSpace\Blog\blob\source</code> 会出现一个CNAME的文件</p></li><li><p>如果没有CNAME文件</p><p>打开你本地博客<code>/source</code>目录，我的是<code>F:\LearnSpace\Blog\blob\source</code>，新建<code>CNAME</code>文件，注意没有后缀。然后在里面写上你的域名，保存。最后运行<code>hexo g</code>、<code>hexo d</code>上传到Github。</p></li></ol><h1 id="六、hexo常用命令"><a href="#六、hexo常用命令" class="headerlink" title="六、hexo常用命令"></a>六、hexo常用命令</h1><pre><code>npm install hexo-cli -g      # 安装hexonpm uninstall hexo-cli -g      # 卸载hexohexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server）hexo deploy #部署到GitHubhexo help  # 查看帮助hexo version  #查看Hexo的版本# 缩写hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy# 组合hexo s -g #生成并本地预览hexo d -g #生成并上传</code></pre><h1 id="七、写博客的规范"><a href="#七、写博客的规范" class="headerlink" title="七、写博客的规范"></a>七、写博客的规范</h1><ol><li><p>_config.yml</p><p>冒号后面必须有一个空格，否则会出问题</p></li><li><p>图片</p><p>引用图片需要把图片放在对应的文件夹中，只需要写文件名就可以了</p></li><li><p>文章头设置</p><p>模板在/scaffolds/post.md</p><pre><code>--- title: {{ title }} # 文章名称date: {{ date }} # 文章生成时间top: false cover: false password: toc: true mathjax: true summary: tags:-- [tag1]-- [tag2]-- [tag3]categories: -- [cat1]---</code></pre></li></ol><h1 id="八、备份博客源文件"><a href="#八、备份博客源文件" class="headerlink" title="八、备份博客源文件"></a>八、备份博客源文件</h1><p>​    博客已经搭建完成，但是博客仓库只是保存生成的静态网页文件，是没有博客源文件的，如果电脑出现了问题，那就麻烦了，所以源文件也需要备份一下。</p><ol><li><p>在<code>Github</code>上创建一个与本地仓库同名的仓库, 我的是<code>hexo-matery</code></p></li><li><p>初始化本地仓库</p><pre class="line-numbers language-shell"><code class="language-shell">git init       添加.gitignore文件.gitignore    .DS_Store    Thumbs.db    *.log    public/    .deploy*/    .vscode/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><ol start="3"><li><p>连接到远程<code>Github</code>,</p><pre class="line-numbers language-shell"><code class="language-shell">git remote add github git@github.com:981935539/hexo-matery.gitgit fetchgit merge --allow-unrelated-histories github/master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>推送本地源文件到<code>Github</code></p><pre class="line-numbers language-shell"><code class="language-shell">git add .git commit -m "第一次备份本地仓库"git push --set-upstream github master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><ol start="5"><li><p>现在在任何一台电脑上, 执行<code>git clonegit@github.com:981935539/hexo-matery.git</code></p><p>就可以把博客源文件复制到本地。</p></li></ol><h1 id="九、Ubuntu安装node-js和hexo"><a href="#九、Ubuntu安装node-js和hexo" class="headerlink" title="九、Ubuntu安装node.js和hexo"></a>九、Ubuntu安装node.js和hexo</h1><pre class="line-numbers language-shell"><code class="language-shell">tar -xvf node-v12.13.0-linux-x64.tar.xzsudo mv node-v12.13.0-linux-x64 /usr/localsudo ln -s /usr/local/node-v12.13.0-linux-x64/bin/node /usr/local/bin/nodesudo ln -s /usr/local/node-v12.13.0-linux-x64/bin/npm /usr/local/bin/npmsudo npm install -g hexosudo ln -s /usr/local/node-v12.13.0-linux-x64/bin/hexo /usr/local/bin/hexo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="十、参考"><a href="#十、参考" class="headerlink" title="十、参考"></a>十、参考</h1><p>​    <a href="https://godweiyang.com/2018/04/13/hexo-blog/#toc-heading-9" target="_blank" rel="noopener">https://godweiyang.com/2018/04/13/hexo-blog/#toc-heading-9</a></p><p>​    <a href="https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html" target="_blank" rel="noopener">https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Github </tag>
            
            <tag> Hexo </tag>
            
            <tag> node.js </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
